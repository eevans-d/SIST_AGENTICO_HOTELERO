# Manual de Operaciones - Sistema Agente Hotelero IA

## üìã √çndice

1. [Arquitectura del Sistema](#arquitectura-del-sistema)
2. [Operaci√≥n Diaria](#operaci√≥n-diaria)
3. [Troubleshooting](#troubleshooting)
4. [Runbooks](#runbooks)
5. [Mantenimiento](#mantenimiento)
6. [Monitoreo y Alertas](#monitoreo-y-alertas)
7. [Recuperaci√≥n de Desastres](#recuperaci√≥n-de-desastres)
8. [Seguridad](#seguridad)

---

## Arquitectura del Sistema

### Componentes Principales

- **agente-api**: API principal FastAPI que orquesta todo el sistema
- **postgres**: Base de datos para sesiones, bloqueos y mapeo de inquilinos
- **redis**: Cach√©, control de velocidad y bloqueos distribuidos
- **qloapps**: Sistema PMS de gesti√≥n hotelera
- **monitoring**: Prometheus, Grafana y AlertManager

### Patrones de Dise√±o Clave

- **Patr√≥n Orquestador**: `orchestrator.py` coordina el flujo completo
- **Circuit Breaker**: Previene cascadas de fallos con servicios externos
- **Mensajes Unificados**: Normaliza comunicaciones de diferentes canales
- **Feature Flags**: Habilita/deshabilita funciones sin redespliegue

## Operaci√≥n Diaria

### Checklist Matutino (08:00 - 5 minutos)

- **Verificar salud:** `curl https://api.agente-hotel.com/health/ready`
- **Revisar logs de errores:** `docker logs agente-api --since="8h" | grep ERROR`
- **Verificar backups:** `ls -la /backups/agente-hotel/daily/`
- **Comprobar estado del circuit breaker:** `curl http://localhost:9090/api/v1/query?query=pms_circuit_breaker_state`
- **Verificar uso de recursos:** `docker stats --no-stream`

### Par√°metros SLO

- `SLO_TARGET` (default 99.0) controla el objetivo global de √©xito del orquestador.
- El error budget = 1 - (SLO_TARGET/100) se inserta din√°micamente en las recording rules al iniciar Prometheus.
- Para cambiarlo: editar `.env`, reiniciar servicio `prometheus` y validar reglas regeneradas.
- Pisos de tr√°fico: las alertas SLO requieren `orchestrator_message_rate_all > 0.5` para evitar falsos positivos en horas valle.

### Gesti√≥n de Feature Flags

```bash
# Listar feature flags actuales
curl http://localhost:8000/admin/feature-flags

# Activar flag espec√≠fico
curl -X POST http://localhost:8000/admin/feature-flags \
  -H "Content-Type: application/json" \
  -d '{"name": "nlp.fallback.enhanced", "enabled": true}'

# Desactivar flag espec√≠fico
curl -X POST http://localhost:8000/admin/feature-flags \
  -H "Content-Type: application/json" \
  -d '{"name": "nlp.fallback.enhanced", "enabled": false}'
```

---

## Troubleshooting

### üî¥ PROBLEMA: WhatsApp No Recibe Mensajes

- **S√≠ntomas**: No llegan mensajes al webhook, error "verificaci√≥n fallida" en logs
- **Diagn√≥stico:** 
  ```bash
  curl "https://.../webhooks/whatsapp?hub.mode=subscribe&hub.challenge=1234&hub.verify_token=YOUR_TOKEN"
  docker-compose logs -f agente-api | grep -i whatsapp
  ```
- **Soluci√≥n:** 
  - Verificar token en `.env.production`
  - Renovar certificado SSL si est√° expirado
  - Revisar logs de NGINX para problemas de conexi√≥n
  - Confirmar que el puerto 443 est√° abierto

### üî¥ PROBLEMA: PMS No Responde

- **S√≠ntomas**: Circuit breaker en estado OPEN, errores 503 en respuestas API
- **Diagn√≥stico:** 
  ```bash
  docker exec agente-api ping qloapps
  docker logs qloapps | tail -n 100
  curl http://localhost:9090/api/v1/query?query=pms_circuit_breaker_state
  ```
- **Soluci√≥n:** 
  ```bash
  # Reiniciar servicios relacionados con PMS
  docker-compose restart qloapps mysql
  
  # Verificar conexi√≥n despu√©s del reinicio
  docker exec agente-api curl -v http://qloapps:8080/api/v1/ping
  
  # Si persiste, verificar configuraci√≥n
  grep -E "^PMS_" .env.production
  ```

### üî¥ PROBLEMA: Alta Latencia en API

- **S√≠ntomas**: Alertas de latencia P95, quejas de usuarios
- **Diagn√≥stico:**
  ```bash
  # Verificar m√©tricas de latencia
  curl http://localhost:9090/api/v1/query?query=histogram_quantile\(0.95,\ rate\(http_request_duration_seconds_bucket\[5m\]\)\)
  
  # Verificar uso de recursos
  docker stats
  
  # Verificar conexiones DB
  docker exec postgres psql -U agente -c "SELECT count(*) FROM pg_stat_activity;"
  ```
- **Soluci√≥n:**
  - Verificar tasa de aciertos de cach√©
  - Comprobar si hay tareas en segundo plano consumiendo recursos
  - Reiniciar el servicio si es necesario
  - Escalar verticalmente recursos si el problema persiste

---

## Runbooks

### üìò RUNBOOK: Confirmar Reserva con Se√±a

1. Verificar comprobante en dashboard.
2. Click en "Confirmar Reserva".
3. Verificar voucher enviado al cliente.
4. Comprobar en logs que se registr√≥ correctamente:
   ```bash
   docker-compose logs agente-api | grep -i "reservation confirmed" | tail -n 20
   ```
5. Verificar sincronizaci√≥n con QloApps:
   ```bash
   curl -H "Authorization: Bearer $PMS_API_KEY" http://qloapps:8080/api/v1/reservations/{ID}
   ```
 
 ### üìò RUNBOOK: Alerta DependencyDown
 - S√≠ntoma: Alertmanager muestra "Alguna dependencia est√° ca√≠da".
 - Diagn√≥stico r√°pido:
	 1) Abrir Grafana ‚Üí Dashboard "Readiness & Dependencies".
	 2) Ver `dependency_up` para identificar cu√°l (database, redis, pms) est√° en 0.
	 3) Revisar `/health/ready` para obtener detalles.
 - Acciones sugeridas:
	 - Database: verificar contenedor `postgres`, logs y conectividad; credenciales en `.env`.
	 - Redis: verificar contenedor `redis`, salud y puertos.
	 - PMS: si `pms_type=mock`, es esperado que est√© en 1; si real, validar `PMS_BASE_URL` y disponibilidad del PMS.
 - Notas: la alerta solo dispara si hubo checks de readiness recientes (<5m) para evitar falsos positivos.

 ### üìò RUNBOOK: OrchestratorHighErrorRate
 - S√≠ntoma: Alertmanager muestra "Alta tasa de errores en Orchestrator".
 - Diagn√≥stico r√°pido:
	 1) Abrir Grafana ‚Üí Dashboard "Agente - Overview".
	 2) Revisar panel "Orchestrator error rate by intent (5m)" para identificar el intent afectado.
	 3) Ver panel "Orchestrator latency p95 by intent" y "PMS API latency p95" para correlacionar con problemas externos.
 - Acciones sugeridas:
	 - Chequear logs de la API (docker compose logs agente-api) filtrando por el intent y correlations IDs.
	 - Validar la salud del PMS (/health/ready, paneles de PMS) si el intent involucra llamadas al PMS.
	 - Si el error aparece en intents de audio, revisar el flujo de STT/TTS.

 ### üìò RUNBOOK: OrchestratorHighLatencyP95
 - S√≠ntoma: Alertmanager muestra "Latencia p95 alta en Orchestrator".
 - Diagn√≥stico r√°pido:
	 1) Grafana ‚Üí "Agente - Overview" ‚Üí panel "Orchestrator latency p95 by intent".
	 2) Correlacionar con "PMS API latency p95" y estado del Circuit Breaker.
	 3) Verificar tasa de requests (carga) y reintentos.
 - Acciones sugeridas:
	 - Escalar horizontalmente `agente-api` si la carga es sostenida.
	 - Revisar latencia y errores del PMS; aplicar circuit breaker/reintentos si no estuvieran activos.
	 - Verificar Redis y Postgres (locks/sesiones/DB) en `/health/ready`.

	 ### üìò RUNBOOK: Orchestrator SLO Degradation
	 - S√≠ntoma: Alertmanager muestra "SLO del Orchestrator en degradaci√≥n" (warning/critical).
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "SLO Health" ‚Üí paneles "Success Rate Global" y "Top 5 Intents by Error %".
		 2) Identificar intents con peor success rate y correlacionar con paneles de error% y p95.
		 3) Revisar dependencia PMS/Redis si los intents involucrados llaman servicios externos.
	 - Acciones sugeridas:
		 - Mitigar intents problem√°ticos: degradaci√≥n controlada, respuestas de fallback.
		 - Abrir incidente si el success rate <97% por m√°s de 10m.
		 - Ajustar umbrales tras an√°lisis de tr√°fico real.
		 - Ajustar piso de tr√°fico (`orchestrator_message_rate_all`) si la alerta no dispara pese a fallos en alto volumen o dispara con volumen muy bajo.

	 ### üìò RUNBOOK: Orchestrator SLO Burn Rate
	 - S√≠ntoma: Alertmanager muestra "SLO burn rate alto/cr√≠tico".
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "SLO Health" ‚Üí paneles de burn rate (fast/slow) y budget usado/restante.
		 2) Confirmar si el burn rate fast y slow superan umbrales (ver anotaciones de la alerta).
	 - Acciones sugeridas:
		 - Aplicar mitigaciones inmediatas en intents top-k con alto error%.
		 - Si cr√≠tico, considerar revertir despliegues recientes relacionados.
		 - Documentar impacto y consumo de error budget en el incidente.
		 - Ajustar `SLO_TARGET` (y por ende error budget) s√≥lo tras an√°lisis post-mortem, nunca durante un incidente activo.

	 ### üìò RUNBOOK: HighHttp5xxRate

	 ### üìò RUNBOOK: SLO Budget Exhaust Forecast
	 - S√≠ntoma: Alertmanager muestra proyecci√≥n de agotamiento (<12h o <6h).
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "SLO Health" ‚Üí panel "Hours to Exhaust Budget".
		 2) Verificar burn rates y budget used.
		 3) Identificar intents top error% / p95.
	 - Acciones sugeridas:
		 - Iniciar acciones de mitigaci√≥n (reducci√≥n de features, fallback responses).
		 - Si cr√≠tico (<6h) escalar a guardia e iniciar plan de reducci√≥n de errores priorizando intents top.
		 - Evaluar si hay despliegue reciente correlacionado.
	 - S√≠ntoma: Alertmanager muestra "Alta tasa de 5xx" en un endpoint.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "Agente - Overview" ‚Üí panel "HTTP 5xx rate (5m)".
		 2) Revisar logs de `agente-api` y NGINX para ese endpoint.
		 3) Correlacionar con "Orchestrator error percentage" si aplica.
	 - Acciones sugeridas:
		 - Identificar excepciones frecuentes en logs y abrir issue.
		 - Validar payloads de entrada (sanitizaci√≥n/validaci√≥n) y dependencias externas.
		 - Implementar manejo de errores y tests si faltan.

	 ### üìò RUNBOOK: HighPmsLatencyP95
	 - S√≠ntoma: p95 de PMS > umbral sostenido.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí panel "PMS API latency p95".
		 2) Verificar estado del PMS (servicios `qloapps`/`mysql`).
		 3) Revisar circuit breaker y reintentos.
	 - Acciones sugeridas:
		 - Aumentar caching en el adapter; validar Redis.
		 - Ajustar timeouts/backoff del adapter.
		 - Coordinar con el equipo del PMS.

	 ### üìò RUNBOOK: PmsCircuitBreakerImminentOpen
	 - S√≠ntoma: Alertas `PmsCircuitBreakerImminentOpenWarning` o `PmsCircuitBreakerImminentOpenCritical` indicando riesgo de apertura.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí panel "Circuit Breaker state" y a√±adir paneles derivados (failure ratios, streak) si no existen.
		 2) Ver panel "PMS API latency p95" y "PMS Errors by type" para correlacionar naturaleza (timeouts vs 5xx).
		 3) Consultar m√©tricas: `pms_cb_failure_streak_fraction`, `pms_cb_failure_ratio_1m`, `pms_cb_minutes_to_open_estimate`.
	 - Posibles causas:
		 - Degradaci√≥n real del PMS (timeouts incrementales).
		 - Cambios recientes en timeouts o thresholds del adapter.
		 - Pico de tr√°fico con patrones no cacheados (incrementa presi√≥n y fallos).
	 - Acciones sugeridas (orden):
		 1) Confirmar que los fallos son leg√≠timos revisando logs (buscar patrones repetidos).
		 2) Si los fallos son timeouts ‚Üí aumentar temporalmente `read` timeout (ej. +50%) y monitorear efecto.
		 3) Activar rutas de degradaci√≥n: limitar intents que disparan llamadas PMS no cr√≠ticas.
		 4) Incrementar TTL de cache de disponibilidad para reducir presi√≥n sobre PMS.
		 5) Coordinar con equipo PMS si latencia/errores se originan upstream.
	 - Mitigaci√≥n preventiva:
		 - Si `pms_cb_minutes_to_open_estimate < 2` y la racha sigue subiendo, aplicar pasos 2‚Äì4 antes de que el breaker abra.
	 - Post-mortem:
		 - Evaluar si `failure_threshold=5` es demasiado bajo para el perfil de error transitorio.
		 - Considerar backoff m√°s agresivo para retries o circuit half-open probabil√≠stico.

	 ### üìò RUNBOOK: CircuitBreakerOpen
	 - S√≠ntoma: Circuit Breaker abierto por m√°s de 2m.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí panel "Circuit Breaker state" (rojo cuando >0).
		 2) Correlacionar con latencia/errores del PMS.
		 3) Logs del adapter para ver causas (rate limit, timeouts, 5xx).
	 - Acciones sugeridas:
		 - Verificar credenciales/endpoints del PMS.
		 - Incrementar l√≠mites/retrys temporalmente si corresponde.
		 - Desplegar mitigaciones (cache warmup, degradaci√≥n controlada).

	 ### üìò RUNBOOK: PmsCacheHitRatio
	 - S√≠ntoma: Alertas `PmsCacheHitRatioLowWarning` o `PmsCacheHitRatioLowCritical`.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí Dashboard "Agente - Overview" ‚Üí panel 21 (hit ratio) y panel 22 (hits vs misses).
		 2) Correlacionar con panel de latencia PMS p95 y estado del Circuit Breaker.
		 3) Verificar en logs si hay patr√≥n de invalidaciones frecuentes (`Invalidated ... cache keys`).
	 - Posibles causas:
		 - TTL demasiado corto (expiraciones antes de reutilizaci√≥n real).
		 - Clave de cache con demasiados par√°metros (alta cardinalidad) ‚Üí baja reutilizaci√≥n.
		 - Invalidation agresiva tras `create_reservation` u otras operaciones de escritura.
		 - Pico de nuevos tipos de consultas (cambio de tr√°fico estacional) a√∫n no calientes.
	 - Acciones sugeridas (orden):
		 1) Confirmar volumen: asegurar actividad >0.2 ops/s (condici√≥n de la alerta).
		 2) Inspeccionar keys representativas en Redis (opcional) para patrones de cardinalidad.
		 3) Ajustar TTL (aumentar) temporalmente si expiraci√≥n temprana es evidente.
		 4) Implementar cache pre-warm (script) para queries populares de disponibilidad (fechas cercanas, room types top).
		 5) Revisar l√≥gica de invalidaci√≥n: evaluar un patr√≥n m√°s espec√≠fico en lugar de `availability:*` completo.
		 6) Si latencia PMS tambi√©n aumenta ‚Üí priorizar mitigaci√≥n y escalar a equipo PMS.
	 - M√©trica clave:
		 `pms_cache_hit_ratio` (recording rule 5m). Objetivo recomendado inicial: >0.8.
	 - Post-mortem:
		 Documentar ajustes (TTL, patrones clave, warm-up) y validar mejora sostenida >24h.

---

## Mantenimiento

### Semanal (Domingos 04:00)

- Limpiar logs antiguos:
  ```bash
  # Eliminar logs m√°s antiguos que 7 d√≠as
  find /var/log/agente-hotel -type f -name "*.log" -mtime +7 -delete
  
  # Comprimir logs m√°s antiguos que 2 d√≠as
  find /var/log/agente-hotel -type f -name "*.log" -mtime +2 -not -name "*.gz" -exec gzip {} \;
  ```
  
- Optimizar base de datos:
  ```bash
  docker exec postgres vacuumdb -U agente --analyze
  ```
  
- Verificar espacio en disco:
  ```bash
  df -h /
  ```
  
- Limpiar im√°genes Docker no utilizadas:
  ```bash
  docker system prune -f
  ```

### Mensual (Primer Domingo del Mes)

- Rotaci√≥n de claves de acceso:
  ```bash
  # Generar nueva API key en QloApps
  # Actualizar .env.production
  nano .env.production
  
  # Reiniciar el servicio para aplicar cambios
  docker-compose -f docker-compose.production.yml restart agente-api
  ```
  
- Verificar certificados SSL:
  ```bash
  # Comprobar fecha de expiraci√≥n
  openssl x509 -enddate -noout -in /etc/nginx/ssl/agente-hotel.com.crt
  ```
  
- Test de recuperaci√≥n:
  ```bash
  # Crear backup de prueba
  make backup ENVIRONMENT=production
  
  # Intentar restauraci√≥n en ambiente de staging
  make restore ENVIRONMENT=staging BACKUP_DATE=$(date +%Y%m%d)_000000
  ```

- Auditor√≠a de seguridad:
  ```bash
  make security
  ```

### Trimestral

- Actualizaci√≥n de dependencias:
  ```bash
  # Actualizar desde repositorio
  git pull origin main
  
  # Actualizar dependencias
  docker-compose -f docker-compose.production.yml build --no-cache
  
  # Reiniciar servicios
  docker-compose -f docker-compose.production.yml down
  docker-compose -f docker-compose.production.yml up -d
  ```
  
- Revisi√≥n de umbrales de alertas:
  ```bash
  # Verificar estad√≠sticas reales vs umbrales
  docker exec prometheus promtool query instant 'histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[30d])) by (le, endpoint))'
  
  # Ajustar umbrales si es necesario
  nano docker/prometheus/rules/slo.rules.yml
  
  # Aplicar cambios
  docker-compose -f docker-compose.production.yml restart prometheus
  ```

## Monitoreo y Alertas

### Dashboards Principales

- **URL**: https://grafana.agente-hotel.com
- **Credenciales**: En `.env.production` (GRAFANA_ADMIN_USER, GRAFANA_ADMIN_PASSWORD)

Dashboards clave:
1. **Agente - Overview**: Vista general del sistema
2. **SLO Health**: M√©tricas de nivel de servicio
3. **PMS Integration**: M√©tricas de integraci√≥n con QloApps
4. **WhatsApp Metrics**: Estad√≠sticas de mensajer√≠a
5. **Resource Utilization**: Uso de recursos del sistema

### M√©tricas Cr√≠ticas

| M√©trica | Descripci√≥n | Umbral Warning | Umbral Critical |
|---------|-------------|----------------|-----------------|
| `pms_circuit_breaker_state` | Estado del circuit breaker (0=cerrado, 1=abierto) | >0 por 1m | >0 por 5m |
| `http_request_duration_seconds` | Latencia de solicitudes API | P95 > 500ms | P95 > 1s |
| `orchestrator_error_ratio` | Tasa de errores del orquestador | >0.01 por 5m | >0.05 por 5m |
| `pms_cache_hit_ratio` | Tasa de aciertos de cach√© | <0.7 | <0.5 |
| `orchestrator_slo_budget_remaining` | Presupuesto de error SLO restante | <50% | <25% |

### Configuraci√≥n de Alertas

Las reglas de alertas est√°n definidas en:
- `docker/prometheus/rules/agente.rules.yml`
- `docker/prometheus/rules/slo.rules.yml`

Canales de notificaci√≥n configurados:
- Slack: #agente-hotel-alerts
- Email: alertas@agente-hotel.com
- PagerDuty: S√≥lo para alertas cr√≠ticas

### Respuesta a Alertas

| Prioridad | Tiempo de Respuesta | Notificaci√≥n | Ejemplo de Alerta |
|-----------|---------------------|--------------|-----------------|
| P1 (Cr√≠tica) | 15 minutos | Slack, Email, PagerDuty | CircuitBreakerOpen, HighErrorRate |
| P2 (Alta) | 30 minutos | Slack, Email | HighLatencyP95, SLOBurnRateFast |
| P3 (Media) | 2 horas | Slack | CacheLowHitRate, HighWarningRate |
| P4 (Baja) | 24 horas | Ticket en sistema | DiskSpaceWarning, SlowGrowth |

---

## Recuperaci√≥n de Desastres

### Plan de Continuidad de Negocio

El sistema est√° dise√±ado para mantener operaciones cr√≠ticas incluso durante eventos disruptivos:

1. **Degradaci√≥n Gradual**: Feature flags permiten deshabilitar funcionalidades no cr√≠ticas
2. **Caching Agresivo**: Redis mantiene datos cr√≠ticos para operaci√≥n offline
3. **Respuestas de Fallback**: NLP configurado con respuestas generales cuando PMS no responde

### Falla Total del Servidor

1. Provisionar nuevo servidor con requisitos m√≠nimos:
   - 4 CPU, 8GB RAM, 100GB SSD
   - Docker y Docker Compose instalados

2. Restaurar desde backup:
   ```bash
   # Clonar repositorio
   git clone https://github.com/eevans-d/SIST_AGENTICO_HOTELERO.git
   cd SIST_AGENTICO_HOTELERO/agente-hotel-api
   
   # Descargar √∫ltimo backup de S3
   aws s3 cp s3://agente-hotel-backups/latest/ ./backups/ --recursive
   
   # Restaurar datos
   ./scripts/restore.sh --backup-date 20251005_153045
   
   # Iniciar servicios
   docker-compose -f docker-compose.production.yml up -d
   ```

3. Actualizar DNS:
   - Apuntar api.agente-hotel.com al nuevo servidor
   - Esperar propagaci√≥n DNS (TTL: 300s)
   
4. Verificar restauraci√≥n:
   ```bash
   # Verificar servicios
   docker-compose -f docker-compose.production.yml ps
   
   # Verificar endpoints de salud
   curl https://api.agente-hotel.com/health/live
   curl https://api.agente-hotel.com/health/ready
   
   # Verificar procesamiento de mensajes
   curl https://api.agente-hotel.com/admin/test-message
   ```

### Recuperaci√≥n de Base de Datos

En caso de corrupci√≥n de datos o fallo en PostgreSQL:

```bash
# Detener servicios que dependen de la base de datos
docker-compose -f docker-compose.production.yml stop agente-api

# Restaurar desde backup espec√≠fico
make restore ENVIRONMENT=production BACKUP_DATE=20251005_153045 DATABASE=postgres

# Reiniciar servicios
docker-compose -f docker-compose.production.yml up -d
```

### Degradaci√≥n Controlada del Servicio

En caso de sobrecarga o problemas severos:

```bash
# Activar modo de degradaci√≥n (deshabilita funciones no cr√≠ticas)
curl -X POST http://localhost:8000/admin/feature-flags \
  -H "Content-Type: application/json" \
  -d '{"name": "service.degradation.enabled", "enabled": true}'

# Aumentar agresividad del caching
curl -X POST http://localhost:8000/admin/cache/ttl \
  -H "Content-Type: application/json" \
  -d '{"pattern": "availability:*", "ttl": 3600}'
```

## Seguridad

### Gesti√≥n de Secretos

- Los secretos est√°n almacenados en archivos `.env.[environment]`
- Nunca se deben commitear estos archivos al repositorio
- Las contrase√±as deben rotarse regularmente seg√∫n la pol√≠tica:
  - API keys: cada 90 d√≠as
  - Contrase√±as DB: cada 180 d√≠as
  - Tokens de acceso: seg√∫n el proveedor

### Verificaciones de Seguridad

```bash
# Escaneo de vulnerabilidades
make security-fast

# An√°lisis de c√≥digo est√°tico
make lint

# Verificaci√≥n de secretos expuestos
gitleaks detect
```

### Logs de Auditor√≠a

Las acciones administrativas se registran en logs de auditor√≠a:

```bash
# Ver logs de acciones administrativas
docker-compose -f docker-compose.production.yml logs agente-api | grep -i "audit"

# Exportar logs de auditor√≠a para cumplimiento
docker-compose -f docker-compose.production.yml logs --since=30d agente-api | grep -i "audit" > /tmp/audit_logs_$(date +%Y%m%d).log
```

### Respuesta a Incidentes de Seguridad

1. **Detecci√≥n**: Alertas autom√°ticas o reporte manual
2. **Contenci√≥n**: Aislar sistemas afectados
3. **Erradicaci√≥n**: Eliminar amenaza y vulnerabilidad
4. **Recuperaci√≥n**: Restaurar servicios desde backup limpio
5. **Lecciones aprendidas**: Documentar y actualizar procesos
