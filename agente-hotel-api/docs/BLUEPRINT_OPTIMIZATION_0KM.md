# üéØ BLUEPRINT OPTIMIZACI√ìN "0 KIL√ìMETROS" - PROYECTO AGENTE HOTELERO

**Fecha Creaci√≥n**: 2025-11-10  
**Objetivo**: Llevar el proyecto al estado √≥ptimo para producci√≥n  
**Estado Inicial**: 8.9/10 readiness | 31% coverage | 28/891 tests passing  
**Estado Objetivo**: 9.5+/10 readiness | 85%+ coverage | 100% tests passing  

---

## üìä AN√ÅLISIS DEL ESTADO ACTUAL

### ‚úÖ Fortalezas Actuales
- ‚úÖ **Seguridad**: 0 CRITICAL CVEs (python-jose 3.5.0 actualizado)
- ‚úÖ **Linting**: 0 errores Ruff + gitleaks
- ‚úÖ **Infraestructura**: 7 servicios Docker Compose funcionando
- ‚úÖ **Secrets**: Auto-generados y seguros (.env.staging)
- ‚úÖ **Observabilidad**: Stack completo (Prometheus/Grafana/Jaeger/AlertManager)
- ‚úÖ **Arquitectura**: Patrones s√≥lidos (Circuit Breaker, Caching, Locks)
- ‚úÖ **Documentaci√≥n Base**: Gu√≠as operacionales + runbooks

### ‚ö†Ô∏è √Åreas Cr√≠ticas de Mejora
- ‚ùå **Coverage**: 31% (objetivo: 85%+) - **CR√çTICO**
- ‚ùå **Tests Passing**: 28/891 (3.1%) - **BLOQUEANTE**
- ‚ö†Ô∏è **Performance**: No baseline establecido
- ‚ö†Ô∏è **Database**: √çndices sin optimizar
- ‚ö†Ô∏è **Caching**: Estrategia b√°sica implementada
- ‚ö†Ô∏è **Observability**: Dashboards incompletos
- ‚ö†Ô∏è **Documentation**: Gaps en docs t√©cnicas

### üìà M√©tricas Clave

| M√©trica | Actual | Objetivo | Gap |
|---------|--------|----------|-----|
| **Test Coverage** | 31% | 85% | -54% |
| **Tests Passing** | 28/891 (3.1%) | 100% | -97% |
| **P95 Latency** | No medido | <200ms | TBD |
| **CVEs CRITICAL** | 0 | 0 | ‚úÖ |
| **Code Quality** | 0 errors | 0 errors | ‚úÖ |
| **Docs Coverage** | ~60% | 95% | -35% |

---

## üó∫Ô∏è ARQUITECTURA DEL BLUEPRINT

### Estructura por M√≥dulos

```
M√ìDULO 1: FOUNDATION (Tests + Coverage)          ‚Üê PRIORIDAD M√ÅXIMA
‚îú‚îÄ‚îÄ 1.1 An√°lisis de tests existentes
‚îú‚îÄ‚îÄ 1.2 Identificar tests rotos
‚îú‚îÄ‚îÄ 1.3 Reparar tests cr√≠ticos
‚îú‚îÄ‚îÄ 1.4 Aumentar coverage al 70%
‚îî‚îÄ‚îÄ 1.5 Validar CI/CD pipeline

M√ìDULO 2: PERFORMANCE OPTIMIZATION              ‚Üê ALTA PRIORIDAD
‚îú‚îÄ‚îÄ 2.1 Establecer baseline de performance
‚îú‚îÄ‚îÄ 2.2 Optimizar queries de base de datos
‚îú‚îÄ‚îÄ 2.3 Implementar √≠ndices estrat√©gicos
‚îú‚îÄ‚îÄ 2.4 Optimizar caching Redis
‚îî‚îÄ‚îÄ 2.5 Reducir latencia P95 < 200ms

M√ìDULO 3: DATABASE EXCELLENCE                   ‚Üê ALTA PRIORIDAD
‚îú‚îÄ‚îÄ 3.1 Dise√±o de √≠ndices (B-tree, GiST, BRIN)
‚îú‚îÄ‚îÄ 3.2 Particionamiento de tablas
‚îú‚îÄ‚îÄ 3.3 Migraciones con Alembic
‚îú‚îÄ‚îÄ 3.4 Backup y recovery procedures
‚îî‚îÄ‚îÄ 3.5 Connection pooling optimization

M√ìDULO 4: OBSERVABILITY & MONITORING            ‚Üê MEDIA PRIORIDAD
‚îú‚îÄ‚îÄ 4.1 Dashboards Grafana completos
‚îú‚îÄ‚îÄ 4.2 Alertas Prometheus configuradas
‚îú‚îÄ‚îÄ 4.3 Tracing distribuido Jaeger
‚îú‚îÄ‚îÄ 4.4 Log aggregation (JSON structured)
‚îî‚îÄ‚îÄ 4.5 SLIs/SLOs/SLAs definidos

M√ìDULO 5: RESILIENCE & CHAOS ENGINEERING        ‚Üê MEDIA PRIORIDAD
‚îú‚îÄ‚îÄ 5.1 Tests de chaos engineering
‚îú‚îÄ‚îÄ 5.2 Validaci√≥n de circuit breakers
‚îú‚îÄ‚îÄ 5.3 Fault injection scenarios
‚îú‚îÄ‚îÄ 5.4 Recovery time testing
‚îî‚îÄ‚îÄ 5.5 Disaster recovery drills

M√ìDULO 6: DOCUMENTATION & KNOWLEDGE TRANSFER    ‚Üê MEDIA PRIORIDAD
‚îú‚îÄ‚îÄ 6.1 Architecture Decision Records (ADRs)
‚îú‚îÄ‚îÄ 6.2 API documentation (OpenAPI)
‚îú‚îÄ‚îÄ 6.3 Developer onboarding guide
‚îú‚îÄ‚îÄ 6.4 Operational runbooks completos
‚îî‚îÄ‚îÄ 6.5 Troubleshooting guides

M√ìDULO 7: DEPLOYMENT & AUTOMATION               ‚Üê BAJA PRIORIDAD
‚îú‚îÄ‚îÄ 7.1 CI/CD pipeline optimization
‚îú‚îÄ‚îÄ 7.2 Canary deployment automation
‚îú‚îÄ‚îÄ 7.3 Blue-green deployment
‚îú‚îÄ‚îÄ 7.4 Rollback automation
‚îî‚îÄ‚îÄ 7.5 Post-deployment validation

M√ìDULO 8: SECURITY HARDENING                    ‚Üê BAJA PRIORIDAD
‚îú‚îÄ‚îÄ 8.1 Penetration testing
‚îú‚îÄ‚îÄ 8.2 OWASP Top 10 validation
‚îú‚îÄ‚îÄ 8.3 Dependency scanning automation
‚îú‚îÄ‚îÄ 8.4 Secret rotation procedures
‚îî‚îÄ‚îÄ 8.5 Security audit trail

M√ìDULO 9: CODE QUALITY & REFACTORING            ‚Üê CONTINUO
‚îú‚îÄ‚îÄ 9.1 Code smell detection
‚îú‚îÄ‚îÄ 9.2 Technical debt reduction
‚îú‚îÄ‚îÄ 9.3 Design patterns enforcement
‚îú‚îÄ‚îÄ 9.4 Type hints al 100%
‚îî‚îÄ‚îÄ 9.5 Docstrings compliance

M√ìDULO 10: FINAL VALIDATION & CERTIFICATION     ‚Üê √öLTIMA FASE
‚îú‚îÄ‚îÄ 10.1 Load testing (1000+ RPS)
‚îú‚îÄ‚îÄ 10.2 Stress testing (peak capacity)
‚îú‚îÄ‚îÄ 10.3 Pre-production smoke tests
‚îú‚îÄ‚îÄ 10.4 Security penetration tests
‚îî‚îÄ‚îÄ 10.5 Production readiness review
```

---

## üìã M√ìDULO 1: FOUNDATION (Tests + Coverage) - FASE CR√çTICA

**Objetivo**: Lograr 70%+ coverage y 100% tests passing  
**Duraci√≥n Estimada**: 6-8 horas  
**Prioridad**: üî¥ CR√çTICA (BLOQUEANTE)

### 1.1 An√°lisis de Tests Existentes

**Tareas**:
```bash
‚úÖ T1.1.1 - Ejecutar test discovery completo
  Comando: pytest --collect-only tests/
  Output: Lista de todos los tests disponibles

‚úÖ T1.1.2 - Generar reporte de coverage actual
  Comando: pytest --cov=app --cov-report=html tests/
  Output: htmlcov/index.html con coverage detallado

‚úÖ T1.1.3 - Identificar m√≥dulos sin coverage
  An√°lisis: grep para encontrar archivos en app/ sin tests

‚úÖ T1.1.4 - Analizar tests rotos (failures + errors)
  Comando: pytest tests/ --tb=short 2>&1 | tee test_failures.log
  Output: Log con todos los fallos
```

**Criterios de √âxito**:
- [x] Inventario completo de 891 tests
- [ ] Reporte HTML de coverage generado
- [ ] Lista de m√≥dulos sin coverage (>30% del c√≥digo)
- [ ] Log de tests rotos con stack traces

**Entregables**:
- `reports/test_inventory.txt` - Lista completa de tests
- `htmlcov/index.html` - Coverage visual
- `reports/modules_without_tests.txt` - Gaps de coverage
- `reports/test_failures.log` - Tests rotos con detalles

---

### 1.2 Identificar y Categorizar Tests Rotos

**Tareas**:
```bash
‚úÖ T1.2.1 - Clasificar fallos por tipo
  Categor√≠as:
    - Import errors (dependencias faltantes)
    - Fixture errors (conftest.py issues)
    - Assertion errors (l√≥gica de tests)
    - Timeout errors (performance issues)
    - Mock errors (mocks mal configurados)

‚úÖ T1.2.2 - Priorizar por criticidad
  P0 (Bloqueante): Tests de servicios core (orchestrator, pms_adapter)
  P1 (Alto): Tests de integraci√≥n
  P2 (Medio): Tests E2E
  P3 (Bajo): Tests de performance (no afectan funcionalidad)

‚úÖ T1.2.3 - Crear matriz de dependencias
  Mapear qu√© tests dependen de qu√© fixtures/mocks
```

**Criterios de √âxito**:
- [ ] Tests categorizados por tipo de fallo
- [ ] Prioridad asignada a cada test roto
- [ ] Matriz de dependencias entre tests y fixtures

**Entregables**:
- `reports/test_failures_categorized.csv` - Fallos categorizados
- `reports/test_priorities.md` - Prioridades P0-P3
- `reports/test_dependencies_matrix.txt` - Mapa de dependencias

---

### 1.3 Reparar Tests Cr√≠ticos (P0 + P1)

**Tareas**:
```bash
‚úÖ T1.3.1 - Reparar import errors
  Acci√≥n: Instalar dependencias faltantes
  Validaci√≥n: pytest --collect-only sin errores

‚úÖ T1.3.2 - Reparar fixture errors en conftest.py
  Acci√≥n: Revisar y corregir fixtures AsyncSession, test_app, etc.
  Validaci√≥n: Tests usando fixtures pasan

‚úÖ T1.3.3 - Reparar tests de orchestrator (P0)
  Archivos:
    - tests/unit/test_orchestrator_basic.py
    - tests/integration/test_orchestrator_circuit_breaker.py
  Validaci√≥n: pytest tests/unit/test_orchestrator*.py -v

‚úÖ T1.3.4 - Reparar tests de PMS adapter (P0)
  Archivos:
    - tests/unit/test_pms_circuit_breaker_state_flow.py
    - tests/unit/test_circuit_breaker.py
  Validaci√≥n: pytest tests/unit/test_pms*.py -v

‚úÖ T1.3.5 - Reparar tests de session manager (P0)
  Archivos:
    - tests/unit/test_session_manager_ttl.py
    - tests/unit/test_session_cleanup.py
  Validaci√≥n: pytest tests/unit/test_session*.py -v

‚úÖ T1.3.6 - Reparar tests de lock service (P0)
  Archivos:
    - tests/unit/test_lock_service.py
    - tests/unit/test_lock_audit_trail.py
  Validaci√≥n: pytest tests/unit/test_lock*.py -v
```

**Criterios de √âxito**:
- [ ] 0 import errors
- [ ] Fixtures en conftest.py funcionan
- [ ] Tests P0 (core services) passing al 100%
- [ ] Tests P1 (integraci√≥n) passing al 80%+

**Entregables**:
- Tests P0 reparados y passing
- Coverage de servicios core >80%
- Commit: "fix(tests): repair P0 critical tests - orchestrator, pms, sessions, locks"

---

### 1.4 Aumentar Coverage al 70%+

**Estrategia por M√≥dulo**:

#### 1.4.1 Orchestrator Service (Objetivo: 85%)
```python
# Nuevos tests necesarios:
‚úÖ test_orchestrator_all_intent_handlers()
‚úÖ test_orchestrator_nlp_confidence_thresholds()
‚úÖ test_orchestrator_fallback_responses()
‚úÖ test_orchestrator_audio_processing_integration()
‚úÖ test_orchestrator_session_state_management()
‚úÖ test_orchestrator_error_handling_all_paths()
```

#### 1.4.2 PMS Adapter (Objetivo: 90%)
```python
# Nuevos tests necesarios:
‚úÖ test_pms_adapter_all_endpoints_mock()
‚úÖ test_pms_adapter_cache_hit_ratio()
‚úÖ test_pms_adapter_cache_invalidation()
‚úÖ test_pms_adapter_retry_logic()
‚úÖ test_pms_adapter_timeout_handling()
‚úÖ test_pms_adapter_metrics_accuracy()
```

#### 1.4.3 Session Manager (Objetivo: 85%)
```python
# Nuevos tests necesarios:
‚úÖ test_session_manager_concurrent_updates()
‚úÖ test_session_manager_ttl_enforcement()
‚úÖ test_session_manager_cleanup_edge_cases()
‚úÖ test_session_manager_metrics_consistency()
```

#### 1.4.4 Message Gateway (Objetivo: 80%)
```python
# Nuevos tests necesarios:
‚úÖ test_message_gateway_all_channels()
‚úÖ test_message_gateway_normalization()
‚úÖ test_message_gateway_tenant_resolution()
‚úÖ test_message_gateway_error_handling()
```

#### 1.4.5 Feature Flag Service (Objetivo: 75%)
```python
# Nuevos tests necesarios:
‚úÖ test_feature_flags_redis_fallback()
‚úÖ test_feature_flags_default_values()
‚úÖ test_feature_flags_cache_refresh()
```

**Criterios de √âxito**:
- [ ] Coverage global ‚â• 70%
- [ ] Coverage servicios cr√≠ticos ‚â• 85%
- [ ] Coverage handlers ‚â• 80%
- [ ] Coverage utils ‚â• 70%

**Entregables**:
- 100+ nuevos tests implementados
- Coverage report HTML >70%
- Commit: "test(coverage): increase coverage to 70%+ across all critical modules"

---

### 1.5 Validar CI/CD Pipeline

**Tareas**:
```bash
‚úÖ T1.5.1 - Configurar pytest en CI
  Crear: .github/workflows/tests.yml
  Incluir: pytest, coverage, reports

‚úÖ T1.5.2 - Badge de coverage en README
  Integrar: codecov.io o coveralls.io

‚úÖ T1.5.3 - Quality gates
  Configurar: Minimum 70% coverage to pass CI
```

**Criterios de √âxito**:
- [ ] CI ejecuta tests autom√°ticamente
- [ ] Coverage reportado en PR
- [ ] Quality gates enforced (70% min)

---

## üìã M√ìDULO 2: PERFORMANCE OPTIMIZATION

**Objetivo**: P95 latency <200ms, throughput >500 RPS  
**Duraci√≥n Estimada**: 4-6 horas  
**Prioridad**: üü† ALTA

### 2.1 Establecer Baseline de Performance

**Tareas**:
```bash
‚úÖ T2.1.1 - Instrumentar endpoints cr√≠ticos
  Endpoints:
    - POST /api/webhooks/whatsapp
    - POST /api/orchestrator/process
    - GET /api/pms/availability

‚úÖ T2.1.2 - Ejecutar load testing
  Herramienta: locust o k6
  Escenario: 100 RPS durante 5 minutos
  M√©tricas: P50, P95, P99 latency

‚úÖ T2.1.3 - Identificar bottlenecks
  Herramientas: py-spy, memory_profiler
  An√°lisis: CPU, memoria, I/O
```

**Criterios de √âxito**:
- [ ] Baseline documentado (latencias actuales)
- [ ] Bottlenecks identificados
- [ ] Plan de optimizaci√≥n priorizado

**Entregables**:
- `reports/performance_baseline.md` - M√©tricas actuales
- `reports/bottlenecks_analysis.md` - An√°lisis detallado
- `reports/optimization_plan.md` - Plan priorizado

---

### 2.2 Optimizar Queries de Base de Datos

**Tareas**:
```bash
‚úÖ T2.2.1 - Identificar N+1 queries
  Herramienta: SQLAlchemy logging + EXPLAIN ANALYZE

‚úÖ T2.2.2 - Implementar eager loading
  T√©cnicas: joinedload(), selectinload()

‚úÖ T2.2.3 - Optimizar queries lentas (>100ms)
  Acci√≥n: Refactorizar queries, agregar √≠ndices

‚úÖ T2.2.4 - Implementar query result caching
  Estrategia: Redis cache para queries frecuentes
```

**Criterios de √âxito**:
- [ ] 0 N+1 queries en hot paths
- [ ] Queries cr√≠ticas <50ms (P95)
- [ ] Cache hit ratio >80% en queries frecuentes

---

### 2.3 Implementar √çndices Estrat√©gicos

**An√°lisis de Queries Frecuentes**:
```sql
-- Identificar queries sin √≠ndices
SELECT schemaname, tablename, seq_scan, idx_scan
FROM pg_stat_user_tables
WHERE seq_scan > idx_scan
ORDER BY seq_scan DESC;
```

**√çndices Propuestos**:
```sql
-- Session Manager (b√∫squedas por sender_id + timestamp)
CREATE INDEX CONCURRENTLY idx_sessions_sender_updated 
ON sessions(sender_id, last_activity DESC);

-- Lock Service (b√∫squedas por resource_id)
CREATE INDEX CONCURRENTLY idx_locks_resource_status 
ON reservation_locks(resource_id, status) 
WHERE status = 'active';

-- Tenant Resolution (b√∫squedas frecuentes)
CREATE INDEX CONCURRENTLY idx_tenant_identifiers_lookup 
ON tenant_user_identifiers(identifier_value, channel);
```

**Criterios de √âxito**:
- [ ] √çndices B-tree en columnas de b√∫squeda
- [ ] √çndices parciales en queries condicionales
- [ ] idx_scan > seq_scan en todas las tablas cr√≠ticas

---

### 2.4 Optimizar Caching Redis

**Estrategia Avanzada**:
```python
# Cache layers:
# L1: In-memory (Python dict) - TTL 60s
# L2: Redis - TTL 5-60min (dependiendo del dato)
# L3: PostgreSQL - Source of truth

‚úÖ T2.4.1 - Implementar cache hierarchy
‚úÖ T2.4.2 - Cache warming para datos frecuentes
‚úÖ T2.4.3 - Cache invalidation patterns
‚úÖ T2.4.4 - Monitorear hit ratio (objetivo: 85%+)
```

**Datos a Cachear**:
```python
# PMS Adapter (TTL 5min)
- Availability data
- Room types

# Feature Flags (TTL 60s)
- Flag values (in-memory + Redis)

# Tenant Resolution (TTL 300s)
- Tenant mappings (dynamic resolution)
```

**Criterios de √âxito**:
- [ ] Cache hit ratio >85%
- [ ] Invalidaci√≥n funciona correctamente
- [ ] M√©tricas de cache tracked en Prometheus

---

### 2.5 Reducir Latencia P95 < 200ms

**Optimizaciones Finales**:
```bash
‚úÖ T2.5.1 - Connection pooling (asyncpg + Redis)
  Configuraci√≥n: pool_size=10, max_overflow=10

‚úÖ T2.5.2 - Async everywhere (no blocking I/O)
  Audit: Buscar operaciones s√≠ncronas en hot paths

‚úÖ T2.5.3 - Background tasks (Celery/arq)
  Tareas: Emails, notificaciones, cleanup

‚úÖ T2.5.4 - CDN para assets est√°ticos
  Considerar: CloudFlare o similar
```

**Criterios de √âxito**:
- [ ] P95 latency <200ms en todos los endpoints
- [ ] P99 latency <500ms
- [ ] No blocking I/O en request handlers

---

## üìã M√ìDULO 3: DATABASE EXCELLENCE

**Objetivo**: DB optimizada, migraciones seguras, backups automatizados  
**Duraci√≥n Estimada**: 3-4 horas  
**Prioridad**: üü† ALTA

### 3.1 Dise√±o de √çndices Avanzados

**√çndices Especializados**:
```sql
-- GiST para b√∫squedas de rangos de fechas
CREATE INDEX idx_reservations_date_range ON reservations 
USING gist (daterange(check_in, check_out));

-- BRIN para tablas grandes con datos ordenados temporalmente
CREATE INDEX idx_sessions_created_brin ON sessions 
USING brin (created_at);

-- Hash index para igualdades exactas (UUID lookups)
CREATE INDEX idx_sessions_id_hash ON sessions 
USING hash (id);
```

**Criterios de √âxito**:
- [ ] √çndices especializados para cada tipo de query
- [ ] EXPLAIN ANALYZE muestra uso de √≠ndices
- [ ] Query performance mejorado >3x

---

### 3.2 Particionamiento de Tablas

**Tablas Candidatas**:
```sql
-- Sessions (particionar por created_at - mensual)
CREATE TABLE sessions_2025_11 PARTITION OF sessions
FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');

-- Lock Audit (particionar por timestamp - mensual)
CREATE TABLE lock_audit_2025_11 PARTITION OF lock_audit
FOR VALUES FROM ('2025-11-01') TO ('2025-12-01');
```

**Criterios de √âxito**:
- [ ] Tablas grandes (>1M rows) particionadas
- [ ] Queries usan partition pruning
- [ ] Mantenimiento simplificado (drop old partitions)

---

### 3.3 Migraciones con Alembic

**Setup**:
```bash
‚úÖ T3.3.1 - Configurar Alembic
  alembic init alembic

‚úÖ T3.3.2 - Generar migraci√≥n inicial
  alembic revision --autogenerate -m "initial schema"

‚úÖ T3.3.3 - Validar migraci√≥n up/down
  alembic upgrade head
  alembic downgrade -1

‚úÖ T3.3.4 - Documentar proceso de migraciones
  Crear: docs/DATABASE_MIGRATIONS.md
```

**Criterios de √âxito**:
- [ ] Alembic configurado y funcionando
- [ ] Migraci√≥n inicial generada
- [ ] Procedimiento de rollback validado

---

### 3.4 Backup y Recovery

**Estrategia**:
```bash
‚úÖ T3.4.1 - Script de backup autom√°tico
  Herramienta: pg_dump con compresi√≥n
  Frecuencia: Daily (0:00 UTC)

‚úÖ T3.4.2 - Retention policy
  Retenci√≥n: 7 daily, 4 weekly, 12 monthly

‚úÖ T3.4.3 - Test de recovery
  Procedimiento: Restaurar backup en DB de test
  Frecuencia: Mensual

‚úÖ T3.4.4 - RPO/RTO definidos
  RPO: <24 horas
  RTO: <1 hora
```

**Criterios de √âxito**:
- [ ] Backups autom√°ticos funcionando
- [ ] Recovery testado y documentado
- [ ] RPO/RTO cumplidos en tests

---

### 3.5 Connection Pooling Optimization

**Configuraci√≥n √ìptima**:
```python
# PostgreSQL (asyncpg)
POSTGRES_POOL_SIZE = 10
POSTGRES_MAX_OVERFLOW = 10
POSTGRES_POOL_TIMEOUT = 30
POSTGRES_POOL_RECYCLE = 3600  # 1 hora

# Redis (aioredis)
REDIS_POOL_SIZE = 20
REDIS_POOL_MIN_SIZE = 5
```

**Monitoreo**:
```python
# M√©tricas a trackear:
- db_connections_active
- db_connections_idle
- db_pool_exhausted_total
- db_connection_wait_time_seconds
```

**Criterios de √âxito**:
- [ ] Pool nunca se agota bajo load normal
- [ ] Connections reutilizadas eficientemente
- [ ] M√©tricas de pool en Grafana

---

## üìã M√ìDULO 4: OBSERVABILITY & MONITORING

**Objetivo**: Visibilidad completa del sistema en producci√≥n  
**Duraci√≥n Estimada**: 3-4 horas  
**Prioridad**: üü° MEDIA

### 4.1 Dashboards Grafana Completos

**Dashboards a Crear**:
```yaml
Dashboard 1: Overview del Sistema
  - Request rate (RPS)
  - Error rate (%)
  - P95/P99 latency
  - Active connections (DB, Redis)

Dashboard 2: PMS Adapter
  - Circuit breaker state
  - PMS API latency
  - Cache hit ratio
  - Error breakdown por endpoint

Dashboard 3: Orchestrator
  - Intents detectados (pie chart)
  - Confidence scores (histogram)
  - Fallback rate
  - Processing latency

Dashboard 4: Database
  - Query latency
  - Connection pool usage
  - Slow queries (>100ms)
  - Index usage

Dashboard 5: Redis
  - Hit ratio
  - Memory usage
  - Evictions
  - Command latency
```

**Criterios de √âxito**:
- [ ] 5 dashboards completos y funcionales
- [ ] Datos en tiempo real (<30s refresh)
- [ ] Alertas visuales en dashboards

---

### 4.2 Alertas Prometheus

**Reglas de Alerta**:
```yaml
# alerts/critical.yml
- alert: HighErrorRate
  expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "Error rate >5% for 5 minutes"

- alert: CircuitBreakerOpen
  expr: pms_circuit_breaker_state == 1
  for: 2m
  labels:
    severity: warning
  annotations:
    summary: "PMS circuit breaker is OPEN"

- alert: DatabaseConnectionPoolExhausted
  expr: db_pool_exhausted_total > 10
  for: 1m
  labels:
    severity: critical
  annotations:
    summary: "DB pool exhausted >10 times in 1 min"

- alert: HighLatency
  expr: histogram_quantile(0.95, http_request_duration_seconds) > 0.5
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "P95 latency >500ms for 5 minutes"
```

**Criterios de √âxito**:
- [ ] 10+ alertas configuradas
- [ ] Alertas enviadas a Slack/Email
- [ ] Runbooks vinculados a cada alerta

---

### 4.3 Tracing Distribuido (Jaeger)

**Configuraci√≥n**:
```python
# Instrumentar spans en:
‚úÖ HTTP requests (entrada/salida)
‚úÖ PMS API calls
‚úÖ Database queries
‚úÖ Redis operations
‚úÖ NLP processing
```

**Criterios de √âxito**:
- [ ] Traces visibles en Jaeger UI
- [ ] Correlaci√≥n entre servicios
- [ ] Identificaci√≥n de cuellos de botella

---

### 4.4 Log Aggregation

**Estrategia**:
```python
# Structured logging (JSON)
logger.info("pms_call_success", 
    endpoint="availability",
    latency_ms=150,
    cache_hit=True,
    correlation_id="abc123"
)
```

**Criterios de √âxito**:
- [ ] Logs en formato JSON estructurado
- [ ] Correlation IDs en todos los logs
- [ ] Logs indexables (Loki/Elasticsearch)

---

### 4.5 SLIs/SLOs/SLAs

**Definiciones**:
```yaml
SLI (Service Level Indicators):
  - Availability: % de uptime
  - Latency: P95 de request duration
  - Error rate: % de requests con 5xx

SLO (Service Level Objectives):
  - Availability: ‚â•99.5% mensual
  - P95 Latency: ‚â§200ms
  - Error rate: ‚â§0.5%

SLA (Service Level Agreements):
  - Availability: ‚â•99% mensual (con penalizaciones)
  - Support response: <4 horas para P0
```

**Criterios de √âxito**:
- [ ] SLIs medidos autom√°ticamente
- [ ] SLOs tracked en dashboards
- [ ] Alertas cuando SLO en riesgo

---

## üìã M√ìDULO 5: RESILIENCE & CHAOS ENGINEERING

**Objetivo**: Sistema resistente a fallos  
**Duraci√≥n Estimada**: 2-3 horas  
**Prioridad**: üü° MEDIA

### 5.1 Chaos Engineering Tests

**Escenarios**:
```python
‚úÖ Scenario 1: PMS API timeout
  - Simular: Inyectar delay de 10s en PMS calls
  - Validar: Circuit breaker abre, fallback funciona

‚úÖ Scenario 2: Redis down
  - Simular: docker stop redis
  - Validar: Sistema degrada gracefully, usa defaults

‚úÖ Scenario 3: PostgreSQL connection loss
  - Simular: Matar conexiones activas
  - Validar: Reconnection autom√°tico funciona

‚úÖ Scenario 4: Spike de tr√°fico (10x normal)
  - Simular: locust con 1000 RPS
  - Validar: Rate limiting funciona, no crashes
```

**Criterios de √âxito**:
- [ ] 4+ escenarios de chaos ejecutados
- [ ] Sistema se recupera autom√°ticamente
- [ ] No data loss en ning√∫n escenario

---

### 5.2 Fault Injection

**Herramienta**: Implementar fault injector
```python
class FaultInjector:
    async def inject_latency(self, delay_ms: int):
        """Inyecta latencia artificial"""
        await asyncio.sleep(delay_ms / 1000)
    
    async def inject_error(self, error_rate: float):
        """Inyecta errores aleatorios"""
        if random.random() < error_rate:
            raise Exception("Injected error")
```

**Criterios de √âxito**:
- [ ] Fault injection framework implementado
- [ ] Tests autom√°ticos con faults
- [ ] M√©tricas de resilience tracked

---

## üìã M√ìDULO 6: DOCUMENTATION

**Objetivo**: Documentaci√≥n completa y actualizada  
**Duraci√≥n Estimada**: 2-3 horas  
**Prioridad**: üü° MEDIA

### 6.1 Architecture Decision Records (ADRs)

**Template ADR**:
```markdown
# ADR-001: Use PostgreSQL for Session Storage

## Status
Accepted

## Context
Need persistent, ACID-compliant storage for user sessions.

## Decision
Use PostgreSQL with asyncpg for async operations.

## Consequences
+ ACID guarantees
+ Rich query capabilities
+ Mature tooling
- Higher latency than Redis for reads
```

**Criterios de √âxito**:
- [ ] 10+ ADRs documentados
- [ ] Decisiones arquitect√≥nicas justificadas
- [ ] Template estandarizado usado

---

### 6.2 API Documentation (OpenAPI)

**Generaci√≥n Autom√°tica**:
```python
# FastAPI auto-genera /docs (Swagger UI)
# Mejorar con:
‚úÖ Descripciones detalladas en endpoints
‚úÖ Ejemplos de requests/responses
‚úÖ Error codes documentados
```

**Criterios de √âxito**:
- [ ] Swagger UI completo y navegable
- [ ] Todos los endpoints documentados
- [ ] Ejemplos funcionales en /docs

---

### 6.3 Developer Onboarding Guide

**Contenido**:
```markdown
# Developer Onboarding Guide

## Day 1: Environment Setup
- Clone repo
- Install dependencies
- Run docker-compose up
- Execute tests

## Day 2: Architecture Understanding
- Read ADRs
- Review system diagram
- Understand key patterns

## Day 3: First Contribution
- Pick "good first issue"
- Make PR with tests
- Code review process
```

**Criterios de √âxito**:
- [ ] Onboarding guide completo
- [ ] New developer can be productive in <3 days
- [ ] Feedback loop para mejorar gu√≠a

---

### 6.4 Runbooks Operacionales

**Runbooks Cr√≠ticos**:
```markdown
‚úÖ Runbook 1: Circuit Breaker Abierto
‚úÖ Runbook 2: Database Slow Queries
‚úÖ Runbook 3: High Memory Usage
‚úÖ Runbook 4: Rate Limit Exceeded
‚úÖ Runbook 5: Deployment Rollback
```

**Criterios de √âxito**:
- [ ] 5+ runbooks completos
- [ ] Vinculados a alertas Prometheus
- [ ] Procedimientos probados en drills

---

## üìã M√ìDULO 7: DEPLOYMENT AUTOMATION

**Objetivo**: Deployments seguros y automatizados  
**Duraci√≥n Estimada**: 2 horas  
**Prioridad**: üü¢ BAJA

### 7.1 CI/CD Pipeline

**GitHub Actions Workflow**:
```yaml
name: CI/CD Pipeline

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        run: make test
      - name: Coverage
        run: make test-coverage
      - name: Quality gates
        run: |
          coverage report --fail-under=70

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Ruff
        run: make lint
      - name: Security scan
        run: make security-fast

  deploy-staging:
    needs: [test, lint]
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to staging
        run: make deploy-staging
```

**Criterios de √âxito**:
- [ ] CI ejecuta en cada PR
- [ ] Quality gates enforcement
- [ ] Auto-deploy a staging en merge

---

### 7.2 Canary Deployment

**Proceso**:
```bash
‚úÖ Step 1: Deploy canary (10% traffic)
‚úÖ Step 2: Monitor metrics (5 min)
‚úÖ Step 3: Compare baseline vs canary
‚úÖ Step 4: Promote or rollback
```

**Criterios de √âxito**:
- [ ] Script de canary deployment
- [ ] M√©tricas comparadas autom√°ticamente
- [ ] Rollback autom√°tico en anomal√≠as

---

## üìã M√ìDULO 8: SECURITY HARDENING

**Objetivo**: Sistema hardened contra ataques  
**Duraci√≥n Estimada**: 2 horas  
**Prioridad**: üü¢ BAJA

### 8.1 OWASP Top 10 Validation

**Checklist**:
```bash
‚úÖ A01 Broken Access Control
  - Rate limiting implementado
  - JWT validation correcta

‚úÖ A02 Cryptographic Failures
  - Secrets en .env, no hardcoded
  - HTTPS enforced

‚úÖ A03 Injection
  - SQLAlchemy ORM (parametrized queries)
  - Input validation

‚úÖ A04 Insecure Design
  - Circuit breakers
  - Fail-safe defaults

‚úÖ A05 Security Misconfiguration
  - Debug=False en prod
  - Security headers (CSP, HSTS)
```

**Criterios de √âxito**:
- [ ] OWASP Top 10 auditado
- [ ] Vulnerabilidades mitigadas
- [ ] Scan autom√°tico en CI

---

### 8.2 Dependency Scanning

**Automatizaci√≥n**:
```bash
# Trivy scan en CI/CD
trivy filesystem --severity HIGH,CRITICAL .

# Safety check (Python packages)
poetry export | safety check --stdin
```

**Criterios de √âxito**:
- [ ] 0 CRITICAL vulnerabilities
- [ ] Auto-scan en cada PR
- [ ] Alertas en nuevas CVEs

---

## üìã M√ìDULO 9: CODE QUALITY

**Objetivo**: C√≥digo limpio y mantenible  
**Duraci√≥n Estimada**: Continuo  
**Prioridad**: üü¢ BAJA (Continuo)

### 9.1 Code Smell Detection

**Herramientas**:
```bash
‚úÖ pylint (code smells)
‚úÖ mypy (type checking)
‚úÖ radon (complexity metrics)
```

**Criterios de √âxito**:
- [ ] Pylint score >8.5/10
- [ ] mypy strict mode passing
- [ ] Cyclomatic complexity <10

---

### 9.2 Type Hints al 100%

**Objetivo**:
```python
# ANTES:
def process_message(msg):
    return orchestrator.handle(msg)

# DESPU√âS:
async def process_message(msg: UnifiedMessage) -> Dict[str, Any]:
    return await orchestrator.handle(msg)
```

**Criterios de √âxito**:
- [ ] Type hints en 100% de funciones p√∫blicas
- [ ] mypy --strict sin errores

---

## üìã M√ìDULO 10: FINAL VALIDATION

**Objetivo**: Certificaci√≥n de producci√≥n  
**Duraci√≥n Estimada**: 3-4 horas  
**Prioridad**: üî¥ FINAL (BLOQUEANTE para producci√≥n)

### 10.1 Load Testing (1000 RPS)

**Escenario**:
```python
# locust configuration
class LoadTest(HttpUser):
    @task
    def webhook_whatsapp(self):
        self.client.post("/api/webhooks/whatsapp", json=payload)
    
    # Target: 1000 RPS durante 10 minutos
```

**Criterios de √âxito**:
- [ ] Sistema maneja 1000 RPS sin crashes
- [ ] P95 latency <500ms bajo load
- [ ] Error rate <0.5%

---

### 10.2 Stress Testing

**Objetivo**: Encontrar l√≠mites del sistema
```bash
‚úÖ Incrementar load hasta fallo
‚úÖ Identificar punto de ruptura
‚úÖ Validar recovery autom√°tico
```

**Criterios de √âxito**:
- [ ] Capacidad m√°xima documentada
- [ ] Sistema se recupera despu√©s de stress
- [ ] Alertas funcionan correctamente

---

### 10.3 Production Readiness Checklist

```markdown
## Infrastructure
- [ ] 7 servicios Docker corriendo
- [ ] Health checks passing
- [ ] Backups configurados

## Testing
- [ ] Coverage ‚â•85%
- [ ] 100% tests passing
- [ ] E2E tests validados

## Performance
- [ ] P95 latency <200ms
- [ ] Throughput >500 RPS
- [ ] Database optimizada

## Observability
- [ ] 5 dashboards Grafana
- [ ] 10+ alertas Prometheus
- [ ] Tracing funcionando

## Security
- [ ] 0 CRITICAL CVEs
- [ ] OWASP Top 10 mitigado
- [ ] Secrets rotados

## Documentation
- [ ] README completo
- [ ] Runbooks operacionales
- [ ] API docs en /docs
```

---

## üéØ PLAN DE EJECUCI√ìN

### Semana 1: Foundation (CR√çTICO)
```
D√≠a 1-2: M√ìDULO 1 (Tests + Coverage)
  - Reparar tests rotos
  - Aumentar coverage a 70%+

D√≠a 3-4: M√ìDULO 2 (Performance)
  - Baseline + optimizaciones
  - P95 <200ms

D√≠a 5: M√ìDULO 3 (Database)
  - √çndices + migraciones
```

### Semana 2: Refinamiento
```
D√≠a 6-7: M√ìDULO 4 (Observability)
  - Dashboards + alertas

D√≠a 8: M√ìDULO 5 (Resilience)
  - Chaos engineering

D√≠a 9: M√ìDULO 6 (Documentation)
  - ADRs + runbooks

D√≠a 10: M√ìDULO 10 (Validation)
  - Load testing + checklist final
```

---

## üìä M√âTRICAS DE √âXITO

### KPIs Principales

| M√©trica | Baseline | Objetivo | Status |
|---------|----------|----------|--------|
| Test Coverage | 31% | 85% | üî¥ |
| Tests Passing | 3.1% | 100% | üî¥ |
| P95 Latency | TBD | <200ms | üü° |
| CVEs CRITICAL | 0 | 0 | ‚úÖ |
| Docs Coverage | 60% | 95% | üü° |
| Uptime | TBD | 99.5% | üü° |

### Definition of Done (DoD)

```markdown
‚úÖ Sistema considera "0 kil√≥metros" cuando:

1. Tests
   - [ ] Coverage ‚â•85% en servicios cr√≠ticos
   - [ ] Coverage ‚â•70% global
   - [ ] 100% tests passing

2. Performance
   - [ ] P95 latency <200ms
   - [ ] P99 latency <500ms
   - [ ] Throughput >500 RPS

3. Database
   - [ ] √çndices optimizados
   - [ ] Migraciones funcionando
   - [ ] Backups autom√°ticos

4. Observability
   - [ ] 5 dashboards Grafana
   - [ ] 10+ alertas configuradas
   - [ ] Tracing end-to-end

5. Resilience
   - [ ] Circuit breakers validados
   - [ ] Chaos tests passing
   - [ ] Recovery autom√°tico

6. Documentation
   - [ ] 10+ ADRs
   - [ ] API docs completa
   - [ ] 5+ runbooks

7. Security
   - [ ] 0 CRITICAL/HIGH CVEs
   - [ ] OWASP Top 10 mitigado
   - [ ] Secrets management

8. Deployment
   - [ ] CI/CD funcionando
   - [ ] Canary deployment
   - [ ] Rollback autom√°tico
```

---

## üöÄ INICIO DE EJECUCI√ìN

**Comando de Inicio**:
```bash
# Crear directorio de trabajo
mkdir -p .playbook/blueprint_0km
cd .playbook/blueprint_0km

# Inicializar tracking
cat > progress.md << EOF
# Blueprint 0KM - Progress Tracking

## Fecha Inicio: 2025-11-10

### M√ìDULO 1: FOUNDATION (Tests + Coverage)
- [ ] T1.1.1 - Test discovery
- [ ] T1.1.2 - Coverage report
...

EOF

# Ejecutar primera tarea
make test --collect-only > test_inventory.txt
```

---

**Pr√≥ximo Paso**: Comenzar ejecuci√≥n M√ìDULO 1.1 (An√°lisis de Tests) üöÄ
