# [PROMPT 3.6] Manual de Operaciones - Agente Hotel

## üìã √çndice

1. [Operaci√≥n Diaria](#operaci√≥n-diaria)
2. [Troubleshooting](#troubleshooting)
3. [Runbooks](#runbooks)
4. [Mantenimiento](#mantenimiento)
5. [Recuperaci√≥n de Desastres](#recuperaci√≥n-de-desastres)

---

## Operaci√≥n Diaria

### Checklist Matutino (08:00 - 5 minutos)

- **Verificar salud:** `curl https://tu-hotel.com.ar/health/ready`
- **Revisar logs de errores:** `docker logs agente-api --since="8h" | grep ERROR`
- **Verificar backups:** `ls -la /backups/agente-hotel/daily/`

### Par√°metros SLO

- `SLO_TARGET` (default 99.0) controla el objetivo global de √©xito del orquestador.
- El error budget = 1 - (SLO_TARGET/100) se inserta din√°micamente en las recording rules al iniciar Prometheus.
- Para cambiarlo: editar `.env`, reiniciar servicio `prometheus` y validar reglas regeneradas.
- Pisos de tr√°fico: las alertas SLO requieren `orchestrator_message_rate_all > 0.5` para evitar falsos positivos en horas valle.

---

## Troubleshooting

### üî¥ PROBLEMA: WhatsApp No Recibe Mensajes

- **Diagn√≥stico:** `curl "https://.../webhooks/whatsapp?hub.mode=subscribe..."`
- **Soluci√≥n:** Verificar token, renovar SSL, revisar logs de NGINX.

### üî¥ PROBLEMA: PMS No Responde

- **Diagn√≥stico:** `docker exec agente-api ping qloapps` y `docker logs qloapps`
- **Soluci√≥n:** `docker-compose restart qloapps mysql`

---

## Runbooks

### üìò RUNBOOK: Confirmar Reserva con Se√±a

1. Verificar comprobante en dashboard.
2. Click en "Confirmar Reserva".
3. Verificar voucher enviado al cliente.
 
 ### üìò RUNBOOK: Alerta DependencyDown
 - S√≠ntoma: Alertmanager muestra "Alguna dependencia est√° ca√≠da".
 - Diagn√≥stico r√°pido:
	 1) Abrir Grafana ‚Üí Dashboard "Readiness & Dependencies".
	 2) Ver `dependency_up` para identificar cu√°l (database, redis, pms) est√° en 0.
	 3) Revisar `/health/ready` para obtener detalles.
 - Acciones sugeridas:
	 - Database: verificar contenedor `postgres`, logs y conectividad; credenciales en `.env`.
	 - Redis: verificar contenedor `redis`, salud y puertos.
	 - PMS: si `pms_type=mock`, es esperado que est√© en 1; si real, validar `PMS_BASE_URL` y disponibilidad del PMS.
 - Notas: la alerta solo dispara si hubo checks de readiness recientes (<5m) para evitar falsos positivos.

 ### üìò RUNBOOK: OrchestratorHighErrorRate
 - S√≠ntoma: Alertmanager muestra "Alta tasa de errores en Orchestrator".
 - Diagn√≥stico r√°pido:
	 1) Abrir Grafana ‚Üí Dashboard "Agente - Overview".
	 2) Revisar panel "Orchestrator error rate by intent (5m)" para identificar el intent afectado.
	 3) Ver panel "Orchestrator latency p95 by intent" y "PMS API latency p95" para correlacionar con problemas externos.
 - Acciones sugeridas:
	 - Chequear logs de la API (docker compose logs agente-api) filtrando por el intent y correlations IDs.
	 - Validar la salud del PMS (/health/ready, paneles de PMS) si el intent involucra llamadas al PMS.
	 - Si el error aparece en intents de audio, revisar el flujo de STT/TTS.

 ### üìò RUNBOOK: OrchestratorHighLatencyP95
 - S√≠ntoma: Alertmanager muestra "Latencia p95 alta en Orchestrator".
 - Diagn√≥stico r√°pido:
	 1) Grafana ‚Üí "Agente - Overview" ‚Üí panel "Orchestrator latency p95 by intent".
	 2) Correlacionar con "PMS API latency p95" y estado del Circuit Breaker.
	 3) Verificar tasa de requests (carga) y reintentos.
 - Acciones sugeridas:
	 - Escalar horizontalmente `agente-api` si la carga es sostenida.
	 - Revisar latencia y errores del PMS; aplicar circuit breaker/reintentos si no estuvieran activos.
	 - Verificar Redis y Postgres (locks/sesiones/DB) en `/health/ready`.

	 ### üìò RUNBOOK: Orchestrator SLO Degradation
	 - S√≠ntoma: Alertmanager muestra "SLO del Orchestrator en degradaci√≥n" (warning/critical).
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "SLO Health" ‚Üí paneles "Success Rate Global" y "Top 5 Intents by Error %".
		 2) Identificar intents con peor success rate y correlacionar con paneles de error% y p95.
		 3) Revisar dependencia PMS/Redis si los intents involucrados llaman servicios externos.
	 - Acciones sugeridas:
		 - Mitigar intents problem√°ticos: degradaci√≥n controlada, respuestas de fallback.
		 - Abrir incidente si el success rate <97% por m√°s de 10m.
		 - Ajustar umbrales tras an√°lisis de tr√°fico real.
		 - Ajustar piso de tr√°fico (`orchestrator_message_rate_all`) si la alerta no dispara pese a fallos en alto volumen o dispara con volumen muy bajo.

	 ### üìò RUNBOOK: Orchestrator SLO Burn Rate
	 - S√≠ntoma: Alertmanager muestra "SLO burn rate alto/cr√≠tico".
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "SLO Health" ‚Üí paneles de burn rate (fast/slow) y budget usado/restante.
		 2) Confirmar si el burn rate fast y slow superan umbrales (ver anotaciones de la alerta).
	 - Acciones sugeridas:
		 - Aplicar mitigaciones inmediatas en intents top-k con alto error%.
		 - Si cr√≠tico, considerar revertir despliegues recientes relacionados.
		 - Documentar impacto y consumo de error budget en el incidente.
		 - Ajustar `SLO_TARGET` (y por ende error budget) s√≥lo tras an√°lisis post-mortem, nunca durante un incidente activo.

	 ### üìò RUNBOOK: HighHttp5xxRate
	 - S√≠ntoma: Alertmanager muestra "Alta tasa de 5xx" en un endpoint.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí "Agente - Overview" ‚Üí panel "HTTP 5xx rate (5m)".
		 2) Revisar logs de `agente-api` y NGINX para ese endpoint.
		 3) Correlacionar con "Orchestrator error percentage" si aplica.
	 - Acciones sugeridas:
		 - Identificar excepciones frecuentes en logs y abrir issue.
		 - Validar payloads de entrada (sanitizaci√≥n/validaci√≥n) y dependencias externas.
		 - Implementar manejo de errores y tests si faltan.

	 ### üìò RUNBOOK: HighPmsLatencyP95
	 - S√≠ntoma: p95 de PMS > umbral sostenido.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí panel "PMS API latency p95".
		 2) Verificar estado del PMS (servicios `qloapps`/`mysql`).
		 3) Revisar circuit breaker y reintentos.
	 - Acciones sugeridas:
		 - Aumentar caching en el adapter; validar Redis.
		 - Ajustar timeouts/backoff del adapter.
		 - Coordinar con el equipo del PMS.

	 ### üìò RUNBOOK: CircuitBreakerOpen
	 - S√≠ntoma: Circuit Breaker abierto por m√°s de 2m.
	 - Diagn√≥stico r√°pido:
		 1) Grafana ‚Üí panel "Circuit Breaker state" (rojo cuando >0).
		 2) Correlacionar con latencia/errores del PMS.
		 3) Logs del adapter para ver causas (rate limit, timeouts, 5xx).
	 - Acciones sugeridas:
		 - Verificar credenciales/endpoints del PMS.
		 - Incrementar l√≠mites/retrys temporalmente si corresponde.
		 - Desplegar mitigaciones (cache warmup, degradaci√≥n controlada).

---

## Mantenimiento

### Semanal (Domingos 04:00)

- Limpiar logs antiguos.
- Optimizar base de datos: `docker exec postgres vacuumdb ...`

---

## Recuperaci√≥n de Desastres

### Falla Total del Servidor

1. Provisionar nuevo servidor.
2. Restaurar √∫ltimo backup desde S3.
3. Ejecutar `./scripts/restore_backup.sh`.
4. Actualizar DNS.
