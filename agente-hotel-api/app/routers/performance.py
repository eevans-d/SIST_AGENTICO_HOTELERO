"""
Performance Optimization API Router para Agente Hotelero IA System
Endpoints para gestión de optimización de performance y escalado automático
"""

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging

from app.services.performance_optimizer import get_performance_optimizer, PerformanceOptimizer
from app.services.database_tuner import get_database_tuner, DatabasePerformanceTuner
from app.services.cache_optimizer import get_cache_optimizer, CacheOptimizer
from app.services.resource_monitor import get_resource_monitor, ResourceMonitor
from app.services.auto_scaler import get_auto_scaler, AutoScaler
from app.core.middleware import rate_limit

# Configurar logging
logger = logging.getLogger(__name__)

# Router para optimización de performance
router = APIRouter(prefix="/api/v1/performance", tags=["Performance Optimization"])

@router.get("/status")
@rate_limit("60/minute")
async def get_performance_status(
    performance_optimizer: PerformanceOptimizer = Depends(get_performance_optimizer),
    resource_monitor: ResourceMonitor = Depends(get_resource_monitor),
    auto_scaler: AutoScaler = Depends(get_auto_scaler)
) -> JSONResponse:
    """
    Obtener estado general de performance del sistema
    """
    try:
        # Obtener reportes de todos los servicios
        perf_report = await performance_optimizer.get_optimization_report()
        resource_report = await resource_monitor.get_resource_report()
        scaling_status = await auto_scaler.get_scaling_status()
        
        status = {
            'system_health': 'healthy',
            'performance_score': perf_report.get('overall_score', 0),
            'resource_usage': {
                'cpu_percent': resource_report.get('current_metrics', {}).get('cpu_percent', 0),
                'memory_percent': resource_report.get('current_metrics', {}).get('memory_percent', 0),
                'disk_percent': resource_report.get('current_metrics', {}).get('disk_percent', 0)
            },
            'active_instances': scaling_status.get('current_instances', {}),
            'active_alerts': len(resource_report.get('active_alerts', [])),
            'optimization_actions_today': perf_report.get('optimizations_today', 0),
            'scaling_decisions_today': scaling_status.get('decisions_today', 0),
            'last_updated': datetime.now().isoformat()
        }
        
        # Determinar salud del sistema
        if resource_report.get('current_metrics', {}).get('cpu_percent', 0) > 85:
            status['system_health'] = 'critical'
        elif resource_report.get('current_metrics', {}).get('memory_percent', 0) > 90:
            status['system_health'] = 'critical'
        elif len(resource_report.get('active_alerts', [])) > 5:
            status['system_health'] = 'warning'
        
        return JSONResponse(content=status)
        
    except Exception as e:
        logger.error(f"Error obteniendo estado de performance: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/metrics")
@rate_limit("30/minute")
async def get_performance_metrics(
    include_predictions: bool = True,
    include_history: bool = False,
    resource_monitor: ResourceMonitor = Depends(get_resource_monitor)
) -> JSONResponse:
    """
    Obtener métricas detalladas de performance
    """
    try:
        resource_report = await resource_monitor.get_resource_report()
        
        metrics = {
            'current_metrics': resource_report.get('current_metrics', {}),
            'thresholds': resource_report.get('thresholds', {}),
            'timestamp': datetime.now().isoformat()
        }
        
        if include_predictions:
            metrics['predictions'] = resource_report.get('predictions', {})
        
        if include_history:
            metrics['metrics_history_count'] = resource_report.get('metrics_history_count', 0)
        
        return JSONResponse(content=metrics)
        
    except Exception as e:
        logger.error(f"Error obteniendo métricas de performance: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/optimization/report")
@rate_limit("20/minute")
async def get_optimization_report(
    performance_optimizer: PerformanceOptimizer = Depends(get_performance_optimizer)
) -> JSONResponse:
    """
    Obtener reporte detallado de optimizaciones
    """
    try:
        report = await performance_optimizer.get_optimization_report()
        return JSONResponse(content=report)
        
    except Exception as e:
        logger.error(f"Error obteniendo reporte de optimización: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/optimization/execute")
@rate_limit("10/minute")
async def execute_optimization(
    background_tasks: BackgroundTasks,
    force: bool = False,
    optimization_types: Optional[List[str]] = None,
    performance_optimizer: PerformanceOptimizer = Depends(get_performance_optimizer)
) -> JSONResponse:
    """
    Ejecutar optimización manual del sistema
    """
    try:
        # Validar tipos de optimización
        valid_types = ['cpu', 'memory', 'database', 'cache', 'api']
        if optimization_types:
            invalid_types = [t for t in optimization_types if t not in valid_types]
            if invalid_types:
                raise HTTPException(
                    status_code=400,
                    detail=f"Tipos de optimización inválidos: {invalid_types}"
                )
        
        # Ejecutar optimización en background
        background_tasks.add_task(
            performance_optimizer.execute_optimization,
            force=force,
            optimization_types=optimization_types or valid_types
        )
        
        return JSONResponse(content={
            'message': 'Optimización iniciada en background',
            'optimization_types': optimization_types or valid_types,
            'force': force,
            'started_at': datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error ejecutando optimización: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/database/report")
@rate_limit("15/minute")
async def get_database_report(
    include_recommendations: bool = True,
    database_tuner: DatabasePerformanceTuner = Depends(get_database_tuner)
) -> JSONResponse:
    """
    Obtener reporte de performance de base de datos
    """
    try:
        report = await database_tuner.get_performance_report()
        
        if not include_recommendations:
            # Remover recomendaciones si no se solicitan
            report.pop('index_recommendations', None)
            report.pop('config_recommendations', None)
        
        return JSONResponse(content=report)
        
    except Exception as e:
        logger.error(f"Error obteniendo reporte de base de datos: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/database/optimize")
@rate_limit("5/minute")
async def optimize_database(
    background_tasks: BackgroundTasks,
    create_indexes: bool = True,
    vacuum_analyze: bool = True,
    optimize_config: bool = False,
    database_tuner: DatabasePerformanceTuner = Depends(get_database_tuner)
) -> JSONResponse:
    """
    Ejecutar optimización de base de datos
    """
    try:
        optimization_tasks = []
        
        if create_indexes:
            optimization_tasks.append("create_recommended_indexes")
        
        if vacuum_analyze:
            optimization_tasks.append("vacuum_analyze_all")
        
        if optimize_config:
            optimization_tasks.append("optimize_database_configuration")
        
        if not optimization_tasks:
            raise HTTPException(
                status_code=400,
                detail="Debe especificar al menos una tarea de optimización"
            )
        
        # Ejecutar optimizations en background
        for task in optimization_tasks:
            background_tasks.add_task(getattr(database_tuner, task))
        
        return JSONResponse(content={
            'message': 'Optimización de base de datos iniciada',
            'tasks': optimization_tasks,
            'started_at': datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error optimizando base de datos: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/cache/report")
@rate_limit("15/minute")
async def get_cache_report(
    include_patterns: bool = True,
    cache_optimizer: CacheOptimizer = Depends(get_cache_optimizer)
) -> JSONResponse:
    """
    Obtener reporte de performance de cache
    """
    try:
        report = await cache_optimizer.get_cache_report()
        
        if not include_patterns:
            # Remover patrones detallados si no se solicitan
            report.pop('cache_patterns', None)
            report.pop('hot_keys', None)
            report.pop('cold_keys', None)
        
        return JSONResponse(content=report)
        
    except Exception as e:
        logger.error(f"Error obteniendo reporte de cache: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/cache/optimize")
@rate_limit("10/minute")
async def optimize_cache(
    background_tasks: BackgroundTasks,
    optimize_ttl: bool = True,
    implement_compression: bool = True,
    preload_data: bool = True,
    cleanup_cache: bool = False,
    cache_optimizer: CacheOptimizer = Depends(get_cache_optimizer)
) -> JSONResponse:
    """
    Ejecutar optimización de cache
    """
    try:
        optimization_tasks = []
        
        if optimize_ttl:
            optimization_tasks.append("optimize_ttl_strategy")
        
        if implement_compression:
            optimization_tasks.append("implement_compression")
        
        if preload_data:
            optimization_tasks.append("preload_hot_data")
        
        if cleanup_cache:
            optimization_tasks.append("cleanup_cache")
        
        if not optimization_tasks:
            raise HTTPException(
                status_code=400,
                detail="Debe especificar al menos una tarea de optimización"
            )
        
        # Ejecutar optimización en background
        background_tasks.add_task(
            cache_optimizer.auto_optimize_cache,
            enable_compression=implement_compression,
            enable_preloading=preload_data,
            enable_cleanup=cleanup_cache
        )
        
        return JSONResponse(content={
            'message': 'Optimización de cache iniciada',
            'tasks': optimization_tasks,
            'started_at': datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error optimizando cache: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/scaling/status")
@rate_limit("30/minute")
async def get_scaling_status(
    auto_scaler: AutoScaler = Depends(get_auto_scaler)
) -> JSONResponse:
    """
    Obtener estado del sistema de escalado automático
    """
    try:
        status = await auto_scaler.get_scaling_status()
        return JSONResponse(content=status)
        
    except Exception as e:
        logger.error(f"Error obteniendo estado de escalado: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/scaling/evaluate")
@rate_limit("10/minute")
async def evaluate_scaling_decisions(
    auto_scaler: AutoScaler = Depends(get_auto_scaler)
) -> JSONResponse:
    """
    Evaluar decisiones de escalado sin ejecutarlas
    """
    try:
        decisions = await auto_scaler.evaluate_scaling_decisions()
        
        decisions_data = []
        for decision in decisions:
            decisions_data.append({
                'service_name': decision.service_name,
                'current_instances': decision.current_instances,
                'target_instances': decision.target_instances,
                'action': decision.action.value,
                'trigger': decision.trigger.value,
                'metric_value': decision.metric_value,
                'threshold': decision.threshold,
                'confidence': decision.confidence,
                'reason': decision.reason,
                'timestamp': decision.timestamp.isoformat()
            })
        
        return JSONResponse(content={
            'decisions': decisions_data,
            'total_decisions': len(decisions),
            'evaluation_time': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error evaluando decisiones de escalado: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/scaling/execute")
@rate_limit("5/minute")
async def execute_scaling_decisions(
    background_tasks: BackgroundTasks,
    auto_scaler: AutoScaler = Depends(get_auto_scaler)
) -> JSONResponse:
    """
    Evaluar y ejecutar decisiones de escalado
    """
    try:
        # Evaluar decisiones
        decisions = await auto_scaler.evaluate_scaling_decisions()
        
        if not decisions:
            return JSONResponse(content={
                'message': 'No hay decisiones de escalado necesarias',
                'decisions_count': 0,
                'timestamp': datetime.now().isoformat()
            })
        
        # Ejecutar decisiones en background
        background_tasks.add_task(auto_scaler.execute_scaling_decisions, decisions)
        
        return JSONResponse(content={
            'message': f'Ejecutando {len(decisions)} decisiones de escalado',
            'decisions_count': len(decisions),
            'services_affected': list(set(d.service_name for d in decisions)),
            'started_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error ejecutando escalado: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.put("/scaling/rule/{service_name}/{rule_name}")
@rate_limit("10/minute")
async def update_scaling_rule(
    service_name: str,
    rule_name: str,
    rule_updates: Dict[str, Any],
    auto_scaler: AutoScaler = Depends(get_auto_scaler)
) -> JSONResponse:
    """
    Actualizar una regla de escalado específica
    """
    try:
        # Validar campos permitidos
        allowed_fields = {
            'threshold_up', 'threshold_down', 'cooldown_seconds',
            'min_instances', 'max_instances', 'scale_up_step',
            'scale_down_step', 'enabled'
        }
        
        invalid_fields = set(rule_updates.keys()) - allowed_fields
        if invalid_fields:
            raise HTTPException(
                status_code=400,
                detail=f"Campos inválidos: {invalid_fields}"
            )
        
        success = await auto_scaler.update_scaling_rule(
            service_name, rule_name, rule_updates
        )
        
        if not success:
            raise HTTPException(
                status_code=404,
                detail=f"Regla {rule_name} no encontrada para servicio {service_name}"
            )
        
        return JSONResponse(content={
            'message': f'Regla {rule_name} actualizada correctamente',
            'service_name': service_name,
            'rule_name': rule_name,
            'updates': rule_updates,
            'updated_at': datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error actualizando regla de escalado: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/alerts")
@rate_limit("20/minute")
async def get_performance_alerts(
    severity: Optional[str] = None,
    resource_type: Optional[str] = None,
    resolved: Optional[bool] = None,
    resource_monitor: ResourceMonitor = Depends(get_resource_monitor)
) -> JSONResponse:
    """
    Obtener alertas de performance con filtros opcionales
    """
    try:
        resource_report = await resource_monitor.get_resource_report()
        alerts = resource_report.get('active_alerts', [])
        
        # Aplicar filtros
        if severity:
            alerts = [a for a in alerts if a.get('severity') == severity]
        
        if resource_type:
            alerts = [a for a in alerts if a.get('resource') == resource_type]
        
        if resolved is not None:
            # Por ahora todas las alertas activas no están resueltas
            if resolved:
                alerts = []  # No hay alertas resueltas en active_alerts
        
        return JSONResponse(content={
            'alerts': alerts,
            'total_alerts': len(alerts),
            'filters_applied': {
                'severity': severity,
                'resource_type': resource_type,
                'resolved': resolved
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error obteniendo alertas de performance: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.post("/alerts/{alert_id}/resolve")
@rate_limit("20/minute")
async def resolve_performance_alert(
    alert_id: str,
    resource_monitor: ResourceMonitor = Depends(get_resource_monitor)
) -> JSONResponse:
    """
    Resolver una alerta de performance específica
    """
    try:
        success = await resource_monitor.resolve_alert(alert_id)
        
        if not success:
            raise HTTPException(
                status_code=404,
                detail=f"Alerta {alert_id} no encontrada"
            )
        
        return JSONResponse(content={
            'message': f'Alerta {alert_id} resuelta correctamente',
            'alert_id': alert_id,
            'resolved_at': datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error resolviendo alerta: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/benchmark")
@rate_limit("5/minute")
async def run_performance_benchmark(
    background_tasks: BackgroundTasks,
    test_duration_seconds: int = 60,
    include_database: bool = True,
    include_cache: bool = True,
    include_api: bool = True
) -> JSONResponse:
    """
    Ejecutar benchmark de performance del sistema
    """
    try:
        if test_duration_seconds < 10 or test_duration_seconds > 300:
            raise HTTPException(
                status_code=400,
                detail="Duración del test debe estar entre 10 y 300 segundos"
            )
        
        benchmark_config = {
            'duration_seconds': test_duration_seconds,
            'include_database': include_database,
            'include_cache': include_cache,
            'include_api': include_api,
            'started_at': datetime.now().isoformat()
        }
        
        # En una implementación real, ejecutaríamos benchmarks específicos
        # Por ahora, retornamos la configuración
        
        return JSONResponse(content={
            'message': 'Benchmark de performance iniciado',
            'config': benchmark_config,
            'estimated_completion': (
                datetime.now().timestamp() + test_duration_seconds
            )
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error ejecutando benchmark: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

@router.get("/recommendations")
@rate_limit("10/minute")
async def get_performance_recommendations(
    performance_optimizer: PerformanceOptimizer = Depends(get_performance_optimizer),
    database_tuner: DatabasePerformanceTuner = Depends(get_database_tuner),
    cache_optimizer: CacheOptimizer = Depends(get_cache_optimizer)
) -> JSONResponse:
    """
    Obtener recomendaciones consolidadas de performance
    """
    try:
        # Obtener recomendaciones de todos los servicios
        perf_report = await performance_optimizer.get_optimization_report()
        db_report = await database_tuner.get_performance_report()
        cache_report = await cache_optimizer.get_cache_report()
        
        recommendations = {
            'system_optimization': perf_report.get('recommendations', []),
            'database_optimization': {
                'indexes': db_report.get('index_recommendations', []),
                'configuration': db_report.get('config_recommendations', [])
            },
            'cache_optimization': cache_report.get('optimization_recommendations', []),
            'priority_actions': [],
            'estimated_impact': {},
            'generated_at': datetime.now().isoformat()
        }
        
        # Generar acciones prioritarias basadas en severidad
        priority_actions = []
        
        # Agregar recomendaciones críticas del sistema
        for rec in perf_report.get('recommendations', []):
            if rec.get('severity') == 'high':
                priority_actions.append({
                    'category': 'system',
                    'action': rec.get('action'),
                    'impact': rec.get('impact', 'medium'),
                    'effort': rec.get('effort', 'medium')
                })
        
        # Agregar recomendaciones críticas de DB
        for rec in db_report.get('index_recommendations', [])[:3]:  # Top 3
            priority_actions.append({
                'category': 'database',
                'action': f"Crear índice: {rec.get('recommended_index')}",
                'impact': 'high',
                'effort': 'low'
            })
        
        recommendations['priority_actions'] = priority_actions
        
        return JSONResponse(content=recommendations)
        
    except Exception as e:
        logger.error(f"Error obteniendo recomendaciones: {e}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")