# ğŸ¯ PLAN DE EJECUCIÃ“N INMEDIATA - ValidaciÃ³n y OptimizaciÃ³n Completa

**Fecha:** 4 de octubre de 2025  
**Objetivo:** Validar ambiente de desarrollo + Implementar herramientas avanzadas + Optimizar infraestructura crÃ­tica  
**DuraciÃ³n Total Estimada:** 90-120 minutos  
**Estado Inicial:** Sprint 1, 2, 3 completados (60%) - Commit 6f5f03d

---

## ğŸ“‹ ESTRUCTURA DEL PLAN

### **FASE A: VALIDACIÃ“N Y TESTING DEL NUEVO ENTORNO** ğŸ§ª
**DuraciÃ³n:** 30-40 minutos  
**Objetivo:** Garantizar que todas las mejoras implementadas funcionan correctamente

### **FASE B: HERRAMIENTAS AVANZADAS (SPRINT 4)** ğŸ› ï¸
**DuraciÃ³n:** 30-40 minutos  
**Objetivo:** Automatizar calidad de cÃ³digo y procesos CI/CD

### **FASE C: OPTIMIZACIÃ“N CRÃTICA DE INFRAESTRUCTURA** ğŸš€
**DuraciÃ³n:** 30-40 minutos  
**Objetivo:** Resolver deudas tÃ©cnicas identificadas y optimizar componentes clave

---

## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## FASE A: VALIDACIÃ“N Y TESTING DEL NUEVO ENTORNO ğŸ§ª
## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### A.1. Pre-ValidaciÃ³n del Sistema (5 min)

#### A.1.1. Verificar Estado Actual
```bash
# Comando 1: Estado Git
git status
git log --oneline -5

# Comando 2: Estado Docker
docker ps -a
docker images | grep agente

# Comando 3: Estado de Servicios
make health
```

**Criterios de Ã‰xito:**
- âœ… Working tree limpio
- âœ… Ãšltimo commit: 6f5f03d
- âœ… Sin contenedores fallidos
- âœ… Health checks pasando

**Acciones si falla:** Resolver conflictos antes de continuar

---

#### A.1.2. Verificar Dependencias Instaladas
```bash
# Comando: Listar paquetes nuevos
poetry show | grep -E "(pytest-cov|pytest-benchmark|pytest-watch)"
```

**Criterios de Ã‰xito:**
- âœ… pytest-cov ~5.0.0
- âœ… pytest-benchmark ~4.0.0
- âœ… pytest-watch ~4.2.0

**Archivo a verificar:** `poetry.lock` debe contener los 8 paquetes nuevos

---

### A.2. Ejecutar Script de Setup Automatizado (10 min)

#### A.2.1. Preparar Ambiente de Prueba
```bash
# Comando 1: Backup de .env actual
cp agente-hotel-api/.env agente-hotel-api/.env.backup.$(date +%Y%m%d_%H%M%S)

# Comando 2: Ejecutar dev-setup.sh
cd agente-hotel-api
chmod +x dev-setup.sh
./dev-setup.sh
```

**Criterios de Ã‰xito:**
- âœ… Script ejecuta sin errores
- âœ… Todos los prerequisitos detectados correctamente
- âœ… Archivo .env creado/actualizado
- âœ… Git hooks instalados en .git/hooks/
- âœ… Dependencias Poetry verificadas
- âœ… ValidaciÃ³n final exitosa

**Validaciones Esperadas:**
1. âœ… Python 3.11+ detectado
2. âœ… Docker + Docker Compose disponibles
3. âœ… Poetry instalado
4. âœ… Git configurado
5. âœ… Secrets generados automÃ¡ticamente
6. âœ… Estructura de directorios validada

**Acciones si falla:**
- Revisar logs del script
- Verificar permisos de ejecuciÃ³n
- Consultar DEBUGGING.md secciÃ³n "Script de Setup"

---

#### A.2.2. Validar Archivos Generados
```bash
# Comando: Verificar archivos crÃ­ticos
ls -la agente-hotel-api/.env
ls -la agente-hotel-api/.git/hooks/pre-commit
ls -la agente-hotel-api/.git/hooks/pre-push
cat agente-hotel-api/.env | grep -E "(SECRET_KEY|JWT_SECRET|ENCRYPTION_KEY)"
```

**Criterios de Ã‰xito:**
- âœ… .env existe y contiene secrets generados (no dummies)
- âœ… Hooks Git instalados y ejecutables
- âœ… Secrets tienen longitud adecuada (â‰¥32 caracteres)

---

### A.3. Probar Comandos Nuevos del Makefile (10 min)

#### A.3.1. Comandos de Desarrollo
```bash
cd agente-hotel-api

# Test 1: Levantar ambiente dev
make dev-up

# Esperar 30 segundos para que servicios inicien
sleep 30

# Test 2: Verificar status
make dev-status

# Test 3: Ver logs
make dev-logs | head -50

# Test 4: Shell interactivo
make dev-shell
# Dentro del shell:
# - python --version
# - pip list | grep pytest
# - exit
```

**Criterios de Ã‰xito:**
- âœ… `dev-up` levanta 8 servicios correctamente
- âœ… `dev-status` muestra todos los servicios "Up" y "healthy"
- âœ… Logs no muestran errores crÃ­ticos
- âœ… Shell interactivo accesible

**Servicios Esperados:**
1. postgres (healthy)
2. redis (healthy)
3. agente-api (healthy)
4. prometheus (healthy)
5. grafana (healthy)
6. adminer (healthy)
7. redis-commander (healthy)
8. mailhog (healthy)

**Acciones si falla:**
- Verificar puertos disponibles (5432, 6379, 8000, 9090, 3000, 8080, 8081, 8025)
- Revisar logs: `docker compose -f docker-compose.dev.yml logs [servicio]`
- Consultar DEBUGGING.md secciÃ³n "Docker Troubleshooting"

---

#### A.3.2. Comandos de Testing
```bash
# Test 1: Cobertura de pruebas
make test-cov

# Test 2: Tests unitarios solamente
make test-unit

# Test 3: Quick check (linting + tests rÃ¡pidos)
make quick-check

# Test 4: Benchmark (si hay tiempo)
make benchmark
```

**Criterios de Ã‰xito:**
- âœ… `test-cov` genera reporte HTML en `htmlcov/`
- âœ… Cobertura â‰¥ 70% (actual: probablemente ~65-75%)
- âœ… `test-unit` ejecuta â‰¥20 tests (actual: 46 tests)
- âœ… `quick-check` completa en <60 segundos
- âœ… `benchmark` genera estadÃ­sticas de performance

**MÃ©tricas Esperadas:**
- Total tests: 46
- Tests unitarios: ~20-25
- Tests integraciÃ³n: ~15-20
- Tests e2e: ~5-10
- Tiempo ejecuciÃ³n: <30 segundos

**Archivos Generados:**
- `htmlcov/index.html` - Reporte de cobertura
- `.coverage` - Base de datos de cobertura
- `.benchmarks/` - Resultados de benchmarks

---

### A.4. Validar Herramientas de Desarrollo (5 min)

#### A.4.1. Acceder a Herramientas Web
```bash
# Abrir en navegador (o verificar con curl):
curl -I http://localhost:8080  # Adminer (PostgreSQL GUI)
curl -I http://localhost:8081  # Redis Commander
curl -I http://localhost:8025  # MailHog
curl -I http://localhost:9090  # Prometheus
curl -I http://localhost:3000  # Grafana
```

**Criterios de Ã‰xito:**
- âœ… Todas las URLs responden 200 OK
- âœ… Adminer conecta a PostgreSQL con credenciales de .env
- âœ… Redis Commander muestra datos de Redis
- âœ… MailHog captura emails de prueba
- âœ… Prometheus muestra mÃ©tricas del agente
- âœ… Grafana tiene dashboards pre-configurados

**Credenciales de Acceso:**
- Adminer: Sistema=PostgreSQL, Servidor=postgres, Usuario/DB/Password desde .env
- Redis Commander: Sin autenticaciÃ³n en dev
- MailHog: Sin autenticaciÃ³n
- Prometheus: Sin autenticaciÃ³n
- Grafana: admin/admin (cambiar en primer login)

---

#### A.4.2. Probar Hot-Reload
```bash
# Test: Modificar archivo y verificar reload automÃ¡tico
echo "# Test hot-reload $(date)" >> agente-hotel-api/app/main.py

# Verificar logs para confirmar reload
docker compose -f docker-compose.dev.yml logs agente-api | tail -20

# Revertir cambio
git checkout agente-hotel-api/app/main.py
```

**Criterios de Ã‰xito:**
- âœ… Cambio detectado en <2 segundos
- âœ… Servicio se recarga automÃ¡ticamente
- âœ… Logs muestran mensaje de reload
- âœ… Sin necesidad de rebuild

**Mensaje Esperado en Logs:**
```
INFO: Detected file change, reloading...
INFO: Application startup complete.
```

---

### A.5. DocumentaciÃ³n y Reporte de ValidaciÃ³n (5 min)

#### A.5.1. Generar Reporte de Cobertura
```bash
# Abrir reporte HTML en navegador
xdg-open agente-hotel-api/htmlcov/index.html
# O en macOS: open htmlcov/index.html
# O simplemente navegar a file:///path/to/htmlcov/index.html
```

**AnÃ¡lisis Esperado:**
- Identificar archivos con cobertura <70%
- Priorizar servicios crÃ­ticos (orchestrator, pms_adapter, message_gateway)
- Listar funciones sin cobertura

---

#### A.5.2. Crear Documento de ValidaciÃ³n
**Archivo:** `VALIDATION_REPORT_FASE_A.md`

**Contenido:**
```markdown
# Reporte de ValidaciÃ³n - Fase A

**Fecha:** 4 de octubre de 2025  
**Ejecutado por:** AI Agent  
**DuraciÃ³n:** [tiempo real]

## Resumen Ejecutivo
- âœ…/âŒ Script dev-setup.sh ejecutado exitosamente
- âœ…/âŒ 8 servicios Docker levantados y healthy
- âœ…/âŒ 16 comandos Makefile funcionales
- âœ…/âŒ Hot-reload operativo (<2s)
- âœ…/âŒ Cobertura de tests: XX%
- âœ…/âŒ Herramientas web accesibles

## Detalles por Componente
[Lista detallada con checks y tiempos]

## Issues Identificados
[Problemas encontrados y resoluciÃ³n]

## Recomendaciones
[Mejoras sugeridas para siguientes fases]
```

---

## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## FASE B: HERRAMIENTAS AVANZADAS (SPRINT 4) ğŸ› ï¸
## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### B.1. Pre-commit Hooks Avanzados (15 min)

#### B.1.1. Configurar Pre-commit Framework
**Archivo:** `agente-hotel-api/.pre-commit-config.yaml`

**Contenido:**
```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=500']
      - id: check-json
      - id: check-merge-conflict
      - id: check-case-conflict
      - id: detect-private-key

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.9
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.5
    hooks:
      - id: bandit
        args: ["-c", "pyproject.toml"]
        additional_dependencies: ["bandit[toml]"]

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.1
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--ignore-missing-imports, --no-strict-optional]

  - repo: local
    hooks:
      - id: pytest-quick
        name: pytest-quick
        entry: poetry run pytest tests/unit -x -v
        language: system
        pass_filenames: false
        always_run: true
```

**InstalaciÃ³n:**
```bash
cd agente-hotel-api
poetry add --group dev pre-commit
poetry run pre-commit install
poetry run pre-commit install --hook-type pre-push
```

**Criterios de Ã‰xito:**
- âœ… Archivo .pre-commit-config.yaml creado
- âœ… pre-commit instalado en Poetry
- âœ… Hooks instalados en .git/hooks/
- âœ… Test manual: `poetry run pre-commit run --all-files` pasa

---

#### B.1.2. Configurar Bandit para Seguridad
**Agregar a:** `agente-hotel-api/pyproject.toml`

**Contenido:**
```toml
[tool.bandit]
exclude_dirs = ["tests", "venv", ".venv"]
tests = ["B201", "B301", "B302", "B303", "B304", "B305", "B306", "B307", "B308", "B309", "B310", "B311", "B312", "B313", "B314", "B315", "B316", "B317", "B318", "B319", "B320", "B321", "B323", "B324", "B325", "B401", "B402", "B403", "B404", "B405", "B406", "B407", "B408", "B409", "B410", "B411", "B412", "B413", "B501", "B502", "B503", "B504", "B505", "B506", "B507", "B601", "B602", "B603", "B604", "B605", "B606", "B607", "B608", "B609", "B610", "B611", "B701", "B702", "B703"]
skips = ["B101", "B601"]  # assert_used, subprocess
```

---

#### B.1.3. Configurar MyPy para Type Checking
**Agregar a:** `agente-hotel-api/pyproject.toml`

**Contenido:**
```toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false  # Gradualmente aumentar
ignore_missing_imports = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
check_untyped_defs = true

[[tool.mypy.overrides]]
module = "tests.*"
ignore_errors = true
```

---

#### B.1.4. Actualizar Makefile con Comandos Pre-commit
**Agregar a:** `agente-hotel-api/Makefile`

```makefile
# ============================================
# PRE-COMMIT HOOKS
# ============================================

.PHONY: pre-commit-install
pre-commit-install: ## Instalar pre-commit hooks
	@echo "ğŸ“¦ Instalando pre-commit..."
	poetry add --group dev pre-commit
	poetry run pre-commit install
	poetry run pre-commit install --hook-type pre-push
	@echo "âœ… Pre-commit hooks instalados"

.PHONY: pre-commit-run
pre-commit-run: ## Ejecutar pre-commit en todos los archivos
	@echo "ğŸ” Ejecutando pre-commit..."
	poetry run pre-commit run --all-files

.PHONY: pre-commit-update
pre-commit-update: ## Actualizar versiones de pre-commit hooks
	@echo "ğŸ”„ Actualizando pre-commit hooks..."
	poetry run pre-commit autoupdate

.PHONY: security-scan
security-scan: ## Escaneo de seguridad con bandit
	@echo "ğŸ”’ Escaneando cÃ³digo con Bandit..."
	poetry run bandit -r app/ -c pyproject.toml

.PHONY: type-check
type-check: ## Type checking con mypy
	@echo "ğŸ” Verificando tipos con MyPy..."
	poetry run mypy app/ --config-file pyproject.toml
```

**Test:**
```bash
make pre-commit-install
make pre-commit-run
make security-scan
make type-check
```

---

### B.2. Pipeline CI Local (10 min)

#### B.2.1. Crear Script de CI Local
**Archivo:** `agente-hotel-api/scripts/ci-local.sh`

**Contenido:**
```bash
#!/bin/bash
set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  ğŸš€ CI LOCAL PIPELINE - Agente Hotel API     â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

START_TIME=$(date +%s)

# Colores
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# FunciÃ³n para reportar pasos
step() {
    echo -e "${BLUE}â–¶ $1${NC}"
}

success() {
    echo -e "${GREEN}âœ“ $1${NC}"
}

error() {
    echo -e "${RED}âœ— $1${NC}"
    exit 1
}

# PASO 1: Linting
step "Paso 1/7: Linting con Ruff..."
if poetry run ruff check app/ tests/ --fix; then
    success "Linting pasado"
else
    error "Linting fallÃ³"
fi

# PASO 2: Formateo
step "Paso 2/7: Verificando formato con Ruff..."
if poetry run ruff format --check app/ tests/; then
    success "Formato correcto"
else
    error "Formato incorrecto - ejecuta 'make fmt'"
fi

# PASO 3: Type Checking
step "Paso 3/7: Type checking con MyPy..."
if poetry run mypy app/ --config-file pyproject.toml --no-error-summary 2>/dev/null || true; then
    success "Type checking completado"
else
    echo -e "${YELLOW}âš  Type checking con warnings (no bloqueante)${NC}"
fi

# PASO 4: Security Scan
step "Paso 4/7: Escaneo de seguridad con Bandit..."
if poetry run bandit -r app/ -c pyproject.toml -lll -q; then
    success "Escaneo de seguridad pasado"
else
    error "Vulnerabilidades de seguridad detectadas"
fi

# PASO 5: Tests Unitarios
step "Paso 5/7: Ejecutando tests unitarios..."
if poetry run pytest tests/unit -v --tb=short; then
    success "Tests unitarios pasados"
else
    error "Tests unitarios fallaron"
fi

# PASO 6: Tests de IntegraciÃ³n
step "Paso 6/7: Ejecutando tests de integraciÃ³n..."
if poetry run pytest tests/integration -v --tb=short; then
    success "Tests de integraciÃ³n pasados"
else
    error "Tests de integraciÃ³n fallaron"
fi

# PASO 7: Coverage Check
step "Paso 7/7: Verificando cobertura de tests..."
if poetry run pytest --cov=app --cov-report=term-missing --cov-fail-under=70 -q; then
    success "Cobertura â‰¥70%"
else
    echo -e "${YELLOW}âš  Cobertura <70% (no bloqueante en local)${NC}"
fi

# Reporte Final
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  âœ… CI LOCAL PIPELINE COMPLETADO              â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo -e "${GREEN}DuraciÃ³n: ${DURATION}s${NC}"
echo ""
echo "ğŸš€ Todo listo para push!"
```

**InstalaciÃ³n:**
```bash
chmod +x agente-hotel-api/scripts/ci-local.sh
```

**Agregar a Makefile:**
```makefile
.PHONY: ci-local
ci-local: ## Ejecutar pipeline CI completo localmente
	@./scripts/ci-local.sh
```

**Test:**
```bash
make ci-local
```

---

#### B.2.2. Integrar CI Local con Pre-push Hook
**Archivo:** `agente-hotel-api/.git/hooks/pre-push` (actualizar)

**Contenido:**
```bash
#!/bin/bash

echo "ğŸš€ Ejecutando CI local antes de push..."
cd "$(git rev-parse --show-toplevel)/agente-hotel-api"

if ./scripts/ci-local.sh; then
    echo "âœ… CI local pasado - procediendo con push"
    exit 0
else
    echo "âŒ CI local fallÃ³ - push bloqueado"
    echo "Ejecuta 'make ci-local' para ver detalles"
    exit 1
fi
```

---

### B.3. AutomatizaciÃ³n de Benchmarks (5 min)

#### B.3.1. Crear Suite de Benchmarks
**Archivo:** `agente-hotel-api/tests/benchmarks/test_performance.py`

**Contenido:**
```python
"""Performance benchmarks for critical paths."""
import pytest
from httpx import AsyncClient
from app.main import app


@pytest.mark.benchmark(group="api")
def test_health_endpoint_performance(benchmark):
    """Benchmark health endpoint response time."""
    async def health_check():
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.get("/health/live")
            assert response.status_code == 200
    
    benchmark(health_check)


@pytest.mark.benchmark(group="orchestrator")
async def test_message_processing_performance(benchmark):
    """Benchmark message orchestration pipeline."""
    from app.services.orchestrator import MessageOrchestrator
    from app.models.unified_message import UnifiedMessage
    
    orchestrator = MessageOrchestrator()
    
    test_message = UnifiedMessage(
        channel="test",
        sender_id="test_user",
        content="Hola, quiero hacer una reserva",
        timestamp=1234567890,
        tenant_id="default"
    )
    
    async def process():
        return await orchestrator.process_message(test_message)
    
    result = benchmark(process)
    assert result is not None


@pytest.mark.benchmark(group="pms")
async def test_pms_adapter_cache_performance(benchmark):
    """Benchmark PMS adapter with cache hits."""
    from app.services.pms_adapter import PMSAdapter
    
    adapter = PMSAdapter()
    
    async def check_availability():
        return await adapter.check_availability(
            hotel_id=1,
            check_in="2025-12-01",
            check_out="2025-12-05"
        )
    
    result = benchmark(check_availability)
    assert result is not None
```

---

#### B.3.2. Configurar Baseline de Performance
**Archivo:** `agente-hotel-api/.benchmarks/baseline.json`

Este archivo se genera automÃ¡ticamente, pero podemos establecer thresholds:

**Agregar a:** `agente-hotel-api/pytest.ini`

```ini
[pytest]
# ... configuraciÃ³n existente ...

# Benchmark configuration
benchmark_max_time = 0.5  # 500ms max por test
benchmark_min_rounds = 5
benchmark_calibration_precision = 10
benchmark_warmup = true
```

---

#### B.3.3. Automatizar ComparaciÃ³n de Benchmarks
**Archivo:** `agente-hotel-api/scripts/benchmark-compare.sh`

**Contenido:**
```bash
#!/bin/bash
# Compara benchmarks actuales con baseline

set -e

echo "ğŸ” Comparando benchmarks con baseline..."

# Ejecutar benchmarks y guardar resultados
poetry run pytest tests/benchmarks/ \
    --benchmark-only \
    --benchmark-json=.benchmarks/current.json

# Si existe baseline, comparar
if [ -f .benchmarks/baseline.json ]; then
    echo "ğŸ“Š Comparando con baseline..."
    poetry run pytest-benchmark compare \
        .benchmarks/baseline.json \
        .benchmarks/current.json \
        --csv=.benchmarks/comparison.csv
    
    echo "âœ… ComparaciÃ³n guardada en .benchmarks/comparison.csv"
else
    echo "âš ï¸  No existe baseline - guardando como referencia"
    cp .benchmarks/current.json .benchmarks/baseline.json
fi
```

**Agregar a Makefile:**
```makefile
.PHONY: benchmark-baseline
benchmark-baseline: ## Establecer baseline de performance
	@echo "ğŸ“Š Estableciendo baseline de performance..."
	poetry run pytest tests/benchmarks/ --benchmark-only --benchmark-json=.benchmarks/baseline.json
	@echo "âœ… Baseline guardado"

.PHONY: benchmark-compare
benchmark-compare: ## Comparar performance con baseline
	@./scripts/benchmark-compare.sh
```

---

## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## FASE C: OPTIMIZACIÃ“N CRÃTICA DE INFRAESTRUCTURA ğŸš€
## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### C.1. AnÃ¡lisis de Deuda TÃ©cnica (10 min)

#### C.1.1. AuditorÃ­a de CÃ³digo
**Ejecutar:**
```bash
cd agente-hotel-api

# 1. Buscar TODOs y FIXMEs
echo "ğŸ” Buscando TODOs y FIXMEs..."
grep -rn "TODO\|FIXME\|XXX\|HACK" app/ --color=always | tee .playbook/todos.txt

# 2. Buscar code smells
echo "ğŸ” Buscando cÃ³digo duplicado..."
poetry run pylint app/ --disable=all --enable=duplicate-code || true

# 3. Complejidad ciclomÃ¡tica
echo "ğŸ” Analizando complejidad..."
poetry run radon cc app/ -a -nb | tee .playbook/complexity.txt

# 4. Mantenibilidad
echo "ğŸ” Analizando mantenibilidad..."
poetry run radon mi app/ -nb | tee .playbook/maintainability.txt
```

**Instalar herramientas si es necesario:**
```bash
poetry add --group dev pylint radon
```

---

#### C.1.2. Crear Reporte de Deuda TÃ©cnica
**Archivo:** `agente-hotel-api/.playbook/TECH_DEBT_REPORT.md`

**Contenido generado automÃ¡ticamente basado en anÃ¡lisis:**
```markdown
# Reporte de Deuda TÃ©cnica

**Fecha:** 4 de octubre de 2025  
**Generado por:** AuditorÃ­a automatizada

## Resumen Ejecutivo
- Total TODOs/FIXMEs: [nÃºmero]
- Archivos con complejidad alta: [lista]
- Ãndice de mantenibilidad promedio: [score]

## Prioridad Alta ğŸ”´
[Issues crÃ­ticos que afectan funcionamiento]

## Prioridad Media ğŸŸ¡
[Issues que afectan mantenibilidad]

## Prioridad Baja ğŸŸ¢
[Mejoras cosmÃ©ticas]

## Recomendaciones
[Acciones prioritarias]
```

---

### C.2. OptimizaciÃ³n de Servicios CrÃ­ticos (15 min)

#### C.2.1. Optimizar PMS Adapter
**AnÃ¡lisis:** Identificar puntos de mejora en `app/services/pms_adapter.py`

**Mejoras a implementar:**

1. **Cache Warming:** Pre-calentar cache al inicio
```python
# Agregar a PMSAdapter.__init__ o mÃ©todo start()
async def warm_cache(self):
    """Pre-warm cache with frequently accessed data."""
    logger.info("Warming PMS cache...")
    try:
        # Cache hotel list
        await self.get_hotels()
        # Cache room types for default hotel
        await self.get_room_types(hotel_id=1)
        logger.info("PMS cache warmed successfully")
    except Exception as e:
        logger.warning(f"Cache warming failed: {e}")
```

2. **Batch Operations:** Agrupar llamadas API
```python
async def check_availability_batch(
    self,
    requests: List[AvailabilityRequest]
) -> List[AvailabilityResponse]:
    """Check availability for multiple requests in batch."""
    # ImplementaciÃ³n con asyncio.gather para paralelizar
    tasks = [
        self.check_availability(
            hotel_id=req.hotel_id,
            check_in=req.check_in,
            check_out=req.check_out
        )
        for req in requests
    ]
    return await asyncio.gather(*tasks, return_exceptions=True)
```

3. **Metrics Enhancement:** Agregar mÃ©tricas detalladas
```python
# Agregar histogram para latencia por endpoint
pms_endpoint_latency = Histogram(
    'pms_endpoint_latency_seconds',
    'PMS API endpoint latency',
    ['endpoint', 'method', 'cache_status']
)

# Usar en cada llamada
with pms_endpoint_latency.labels(
    endpoint='/availability',
    method='GET',
    cache_status='hit' if from_cache else 'miss'
).time():
    result = await self._make_request(...)
```

---

#### C.2.2. Optimizar Orchestrator
**Archivo:** `app/services/orchestrator.py`

**Mejoras:**

1. **Pipeline Paralelo:** Paralelizar operaciones independientes
```python
async def process_message(self, message: UnifiedMessage) -> Response:
    """Process message with parallel operations where possible."""
    
    # Operaciones paralelas
    intent_task = asyncio.create_task(self.nlp.detect_intent(message.content))
    session_task = asyncio.create_task(self.session_manager.get_session(message.sender_id))
    
    intent, session = await asyncio.gather(intent_task, session_task)
    
    # Continuar con lÃ³gica secuencial...
```

2. **Circuit Breaker para NLP:** Proteger llamadas a NLP
```python
from app.core.circuit_breaker import CircuitBreaker

class MessageOrchestrator:
    def __init__(self):
        self.nlp_circuit = CircuitBreaker(
            failure_threshold=5,
            recovery_timeout=30.0,
            expected_exception=NLPError
        )
    
    async def _safe_nlp_call(self, text: str):
        """NLP call with circuit breaker."""
        async with self.nlp_circuit:
            return await self.nlp.detect_intent(text)
```

3. **Request Deduplication:** Evitar procesar mensajes duplicados
```python
from aiocache import Cache

class MessageOrchestrator:
    def __init__(self):
        self.dedup_cache = Cache(Cache.REDIS)
    
    async def is_duplicate(self, message: UnifiedMessage) -> bool:
        """Check if message was recently processed."""
        key = f"msg:{message.sender_id}:{hash(message.content)}"
        if await self.dedup_cache.exists(key):
            return True
        await self.dedup_cache.set(key, 1, ttl=60)  # 60s window
        return False
```

---

#### C.2.3. Optimizar Session Manager
**Archivo:** `app/services/session_manager.py`

**Mejoras:**

1. **Session Pooling:** Reusar conexiones DB
```python
from sqlalchemy.pool import QueuePool

# En database.py, configurar pool
engine = create_async_engine(
    settings.postgres_url,
    poolclass=QueuePool,
    pool_size=10,
    max_overflow=20,
    pool_pre_ping=True,  # Validar conexiones
    pool_recycle=3600,   # Reciclar cada hora
)
```

2. **Lazy Loading:** Cargar datos de sesiÃ³n bajo demanda
```python
class Session:
    _conversation_history: Optional[List[Message]] = None
    
    async def get_conversation_history(self):
        """Lazy load conversation history."""
        if self._conversation_history is None:
            self._conversation_history = await self._load_history()
        return self._conversation_history
```

3. **Session Cleanup:** Limpiar sesiones expiradas automÃ¡ticamente
```python
async def cleanup_expired_sessions(self):
    """Remove expired sessions from DB and cache."""
    cutoff = datetime.now() - timedelta(hours=24)
    
    # Cleanup DB
    await self.db.execute(
        delete(SessionModel).where(SessionModel.updated_at < cutoff)
    )
    
    # Cleanup Redis
    cursor = 0
    while True:
        cursor, keys = await self.redis.scan(
            cursor,
            match="session:*",
            count=100
        )
        for key in keys:
            ttl = await self.redis.ttl(key)
            if ttl < 0:  # Sin TTL o expirado
                await self.redis.delete(key)
        if cursor == 0:
            break
```

---

### C.3. ConfiguraciÃ³n de Monitoring Avanzado (5 min)

#### C.3.1. Agregar Custom Metrics
**Archivo:** `app/services/metrics_service.py`

**Agregar mÃ©tricas de negocio:**
```python
from prometheus_client import Counter, Histogram, Gauge

# Business metrics
reservations_total = Counter(
    'hotel_reservations_total',
    'Total reservations created',
    ['status', 'channel', 'room_type']
)

reservation_value = Histogram(
    'hotel_reservation_value_euros',
    'Reservation value in euros',
    buckets=[50, 100, 200, 500, 1000, 2000, 5000]
)

active_conversations = Gauge(
    'hotel_active_conversations',
    'Number of active guest conversations'
)

guest_satisfaction = Histogram(
    'hotel_guest_satisfaction_score',
    'Guest satisfaction score (1-5)',
    buckets=[1, 2, 3, 4, 5]
)

# Usage example
reservations_total.labels(
    status='confirmed',
    channel='whatsapp',
    room_type='deluxe'
).inc()

reservation_value.observe(450.00)
```

---

#### C.3.2. Configurar Alertas de Negocio
**Archivo:** `docker/alertmanager/config.yml`

**Agregar reglas de alertas:**
```yaml
# Agregar a secciÃ³n route.routes
- match:
    severity: business
  receiver: business-alerts
  group_by: ['alertname', 'channel']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h

# Agregar nuevo receiver
receivers:
  - name: business-alerts
    webhook_configs:
      - url: 'http://agente-api:8000/webhooks/alerts/business'
        send_resolved: true
```

**Archivo:** `docker/prometheus/prometheus.yml`

**Agregar reglas de alertas de negocio:**
```yaml
groups:
  - name: business_alerts
    interval: 30s
    rules:
      - alert: HighReservationFailureRate
        expr: |
          (
            sum(rate(hotel_reservations_total{status="failed"}[5m]))
            /
            sum(rate(hotel_reservations_total[5m]))
          ) > 0.1
        for: 5m
        labels:
          severity: business
          team: operations
        annotations:
          summary: "Alta tasa de fallo en reservas ({{ $value | humanizePercentage }})"
          description: "MÃ¡s del 10% de reservas estÃ¡n fallando en los Ãºltimos 5 minutos"

      - alert: LowGuestSatisfaction
        expr: |
          avg(hotel_guest_satisfaction_score) < 3.0
        for: 1h
        labels:
          severity: business
          team: customer_success
        annotations:
          summary: "SatisfacciÃ³n de huÃ©spedes baja ({{ $value }})"
          description: "La satisfacciÃ³n promedio estÃ¡ por debajo de 3.0"

      - alert: PMSIntegrationDown
        expr: |
          pms_circuit_breaker_state == 1
        for: 2m
        labels:
          severity: critical
          team: engineering
        annotations:
          summary: "IntegraciÃ³n PMS caÃ­da"
          description: "Circuit breaker del PMS estÃ¡ OPEN - sistema degradado"
```

---

#### C.3.3. Crear Dashboard de Negocio en Grafana
**Archivo:** `docker/grafana/dashboards/business_metrics.json`

**Contenido:** (Extracto de dashboard JSON)
```json
{
  "dashboard": {
    "title": "Hotel Business Metrics",
    "panels": [
      {
        "title": "Reservations by Channel",
        "targets": [
          {
            "expr": "sum(rate(hotel_reservations_total[5m])) by (channel)"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Average Reservation Value",
        "targets": [
          {
            "expr": "histogram_quantile(0.5, sum(rate(hotel_reservation_value_euros_bucket[5m])) by (le))"
          }
        ],
        "type": "stat"
      },
      {
        "title": "Active Conversations",
        "targets": [
          {
            "expr": "hotel_active_conversations"
          }
        ],
        "type": "gauge"
      },
      {
        "title": "Guest Satisfaction Trend",
        "targets": [
          {
            "expr": "avg(hotel_guest_satisfaction_score)"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

---

## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## RESUMEN Y VALIDACIÃ“N FINAL
## â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### Checklist Final de ValidaciÃ³n

#### Fase A: âœ… ValidaciÃ³n Completa
- [ ] dev-setup.sh ejecutado exitosamente
- [ ] 8 servicios Docker healthy
- [ ] 16 comandos Makefile funcionan
- [ ] Hot-reload operativo (<2s)
- [ ] Cobertura â‰¥70%
- [ ] Herramientas web accesibles
- [ ] VALIDATION_REPORT_FASE_A.md creado

#### Fase B: âœ… Herramientas Avanzadas
- [ ] .pre-commit-config.yaml configurado
- [ ] Pre-commit hooks instalados
- [ ] CI local pipeline funcional
- [ ] Benchmarks ejecutÃ¡ndose
- [ ] Baseline de performance establecido
- [ ] 6 comandos nuevos en Makefile funcionan

#### Fase C: âœ… OptimizaciÃ³n Infraestructura
- [ ] Reporte de deuda tÃ©cnica generado
- [ ] PMS Adapter optimizado (cache warming, batch, metrics)
- [ ] Orchestrator optimizado (parallel, circuit breaker, deduplication)
- [ ] Session Manager optimizado (pooling, lazy loading, cleanup)
- [ ] MÃ©tricas de negocio implementadas
- [ ] Alertas de negocio configuradas
- [ ] Dashboard Grafana actualizado

---

## ğŸ“Š MÃ‰TRICAS DE Ã‰XITO

### Mejoras Esperadas

#### Performance
- âœ… Tiempo de setup: 30min â†’ 5min (83% reducciÃ³n)
- âœ… Hot-reload: <2s (vs rebuild 60s+)
- âœ… Tests coverage: +10-15% absoluto
- âœ… CI local: <60s ejecuciÃ³n completa
- âœ… PMS latency: -20-30% con optimizaciones

#### Developer Experience
- âœ… +16 comandos Makefile Ãºtiles
- âœ… +8 herramientas de desarrollo integradas
- âœ… +6 hooks automatizados
- âœ… DocumentaciÃ³n completa (DEBUGGING.md, VALIDATION_REPORT)

#### Code Quality
- âœ… Linting automÃ¡tico en commits
- âœ… Security scan en CI
- âœ… Type checking integrado
- âœ… Benchmark tracking continuo

#### Observability
- âœ… +4 mÃ©tricas de negocio
- âœ… +3 alertas crÃ­ticas
- âœ… Dashboard business completo

---

## ğŸ¯ COMANDOS DE EJECUCIÃ“N

### Para Ejecutar Plan Completo
```bash
# Fase A: ValidaciÃ³n
cd agente-hotel-api
./dev-setup.sh
make dev-up
make dev-status
make test-cov
make quick-check

# Fase B: Herramientas Avanzadas
make pre-commit-install
make pre-commit-run
make ci-local
make benchmark-baseline

# Fase C: OptimizaciÃ³n
# (Cambios en cÃ³digo - aplicar manualmente)
make fmt
make lint
make test
make dev-restart

# ValidaciÃ³n Final
make full-check
```

---

## ğŸ“ ENTREGABLES

1. **VALIDATION_REPORT_FASE_A.md** - Reporte de validaciÃ³n ambiente dev
2. **.pre-commit-config.yaml** - ConfiguraciÃ³n hooks pre-commit
3. **scripts/ci-local.sh** - Pipeline CI local
4. **scripts/benchmark-compare.sh** - ComparaciÃ³n benchmarks
5. **tests/benchmarks/test_performance.py** - Suite benchmarks
6. **.playbook/TECH_DEBT_REPORT.md** - Reporte deuda tÃ©cnica
7. **app/services/*_optimized.py** - Servicios optimizados
8. **docker/grafana/dashboards/business_metrics.json** - Dashboard negocio
9. **docker/prometheus/prometheus.yml** - Alertas actualizadas
10. **Makefile** - +6 comandos nuevos

---

## ğŸš€ TIEMPO ESTIMADO TOTAL

- **Fase A:** 30-40 minutos
- **Fase B:** 30-40 minutos  
- **Fase C:** 30-40 minutos  
- **TOTAL:** 90-120 minutos (1.5-2 horas)

---

## âœ… CRITERIOS DE ACEPTACIÃ“N

### Must Have (Obligatorios)
1. âœ… Todos los tests pasan (46/46)
2. âœ… Cobertura â‰¥70%
3. âœ… CI local exitoso
4. âœ… Sin vulnerabilidades HIGH/CRITICAL
5. âœ… Docker compose dev funcional
6. âœ… Hot-reload operativo

### Should Have (Deseables)
1. âœ… Pre-commit hooks instalados
2. âœ… Benchmarks establecidos
3. âœ… MÃ©tricas de negocio implementadas
4. âœ… DocumentaciÃ³n actualizada

### Nice to Have (Opcionales)
1. âšª Type coverage >80%
2. âšª Deuda tÃ©cnica <10 issues HIGH
3. âšª Dashboard business completo

---

**FIN DEL PLAN - LISTO PARA EJECUCIÃ“N** âœ…
